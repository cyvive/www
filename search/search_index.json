{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"60 Second Overview Why? The modern Information Technology Development Approach is based on Speed, Scale Margin . As a result organizations of all sizes are embracing the Cloud Native approach to designing, building and running applications based on Infrastructure-as-a-Service (IaaS) in combination with operational tools and services such as Continous Integration (CI), Continous Deployment (CD), Containers, and Orchestrators. To execute Cloud Native five layers are required: Infrastructure (Bare Metal / Cloud) Provisioning Runtme Orchestration Management Application Definition / Development This simplistic layering opens a world of choices, when combined with the reality that some tools in one layer work better with specific tools than others, a complex exponential selection process is established. There is a strong market need for simplicity, sanity and control of the n+1 choices available when using Cloud Native architecture. What? Cyvive, simply is Immutable Change , applied through all Cloud Native layers and beyond. This means your business, or parts of it can be reproduced, moved or upgraded safely. Cyvive enables this through: Immutable Operational Platform Infrastructure-as-a-Service, expects the cloud service provider to deliver infrastructure components that would otherwise exist in an on-premises data center. These components could consist of servers, storage and networking as well as the virtualization layer, which the (Cloud Service Provider CSP) IaaS provider hosts in its own data center. While they may also provide Platform-as-a-Service (PaaS) offerings such as cloud functions, container execution api's, or even Kubernetes variations. By design, they are not turn-key offerings. Cyvive , however, is. As an operational platform, it directly interfaces with the cloud provider (or Bare Metal) of choice using the provides IaaS interactions to provision an immutable collection of components necessary to run the orchestrator of choice. The default being Kubernetes Governance MicroServices are a suite of applications providing a specific function. They are also a key part of Cloud Native architecture, and while there are many benefits to adopting this model over alternatives such as OSIMM / TOSCA. Orchestration Management alone is insufficient and inefficient to managing complex deployments as each has independent release cycles. The defacto approach to MicroServices is to run them within a container, in most situations, even the functions / serverless approach ultimately runs within a container. As such to actually execute the code, open source and propriatory libraries (which are regularly updated) are aggregated into the container, where to comply with security and zero day vulnerability patching must be updated regularly. Ironically, 50 MicroServices are often the tipping point for unmanagable complexity. 50 MicroServices can have a maximum of 1225 interactions, versions, and dependencies between eachother. It is also a realistic expectation that at least one of the Open Source libraries used in each MicroService will need to be updated, tested and validated as production safe every couple of days. Potentially 700 redeploys a month. While the Continous Integration System may validate the code is safe, by nature MicroServices require Continous Deployment / Promotion through environmental complexity to proove they are production stable. MicroServices also have their own independent dependency graph, so actual deployments may not be as simple as replacing a single service in isolation each time. Cyvive , as the Premier MicroService Governance solution, streamlines all complexities through dynamic dependency graphs, an industry standard configuration communication syntax, release management, configuration and version management for MicroServices through to Infrastructure. Any part of your infrastructure can be deployed on-demand, with all relevant dependent services, in any environment. EcoSystem Cloud Native requires a collection of tools, or an extended ecosystem of services to understand and, unlock and leverage its full potential. Each tool, when selected by companies typically goes through a process, that takes months for an efficient team with multitudes of Proof of Concepts, each potentially causing back to the drawing board moments . The modern company doesn't have the luxury of time to assess, stabilize and incrementally add each component of the Cloud Native ecosystem while guaranteeing stability amongst change management in their Digital Transformation journey. Cyvive takes the best in breed tool for each part of the EcoSystem and manages its lifecycle. Choices are available between Open Source or Propriatory where possible. Such careful selection and management of the Best in Breed Candidates of the EcoSystem unlocks the power of the Orchestrator to perform often significantly beyond its standard capabilities Cloud Agnostic It is no longer a realistic expectation that companies can enhance their technology stack by partnering with a single cloud provider. With the growing multitude of high quality cloud providers, each offering niche tools a multi-cloud strategy is a necessity. Cyvive 's detailed Governance and Operational Capabilities allow rapid movement of workloads between cloud providers at an unprecidented scale. It is now a realistic expectation that every hour your entire company can be migrated between clouds based on lowest instance pricing. Without disruption of service. How? We worked with 3 Universities, and over 35 industry publications to analyse trends and approaches to modelling, scaling, interacting and managing MicroService deployents at diabolical scale. The result is the core configuration language of Cyvive , a direct extension of natural descriptive language used in companies today. We also cross partnered to understand and explore each part of the Cloud Native EcoSystem to architect and craft a well-balanced blend of services capable of supporting over 2,500 nodes with 500 containers each. (Yes, Cyvive has been applied to managing over 1 million containers) We pushed immutability down to the operating system, every machine self registers, and is managed exclusively by Cyvive . There is no human access available to the actual machine. Making Cyvive inaccessible to human error. While Cyvive is orchestrator independent, it has been actively used with Kubernetes since version 1.6.x (March 2017) Finally, we selected Terraform for cloud provider bare metal interactions. Properly tuned, full immutable lifecyle management was possible while leveraging all the important functionalities of major cloud providers. Where? All Major Public Clouds AMD64 / ARM64 Chipsets Bare Metal ( Cyvive creates its own cloud on metal) Cyvive : The Premier Cloud Agnostic Operation Governance Platform","title":"Cyvive"},{"location":"#60-second-overview","text":"","title":"60 Second Overview"},{"location":"#why","text":"The modern Information Technology Development Approach is based on Speed, Scale Margin . As a result organizations of all sizes are embracing the Cloud Native approach to designing, building and running applications based on Infrastructure-as-a-Service (IaaS) in combination with operational tools and services such as Continous Integration (CI), Continous Deployment (CD), Containers, and Orchestrators. To execute Cloud Native five layers are required: Infrastructure (Bare Metal / Cloud) Provisioning Runtme Orchestration Management Application Definition / Development This simplistic layering opens a world of choices, when combined with the reality that some tools in one layer work better with specific tools than others, a complex exponential selection process is established. There is a strong market need for simplicity, sanity and control of the n+1 choices available when using Cloud Native architecture.","title":"Why?"},{"location":"#what","text":"Cyvive, simply is Immutable Change , applied through all Cloud Native layers and beyond. This means your business, or parts of it can be reproduced, moved or upgraded safely. Cyvive enables this through:","title":"What?"},{"location":"#immutable-operational-platform","text":"Infrastructure-as-a-Service, expects the cloud service provider to deliver infrastructure components that would otherwise exist in an on-premises data center. These components could consist of servers, storage and networking as well as the virtualization layer, which the (Cloud Service Provider CSP) IaaS provider hosts in its own data center. While they may also provide Platform-as-a-Service (PaaS) offerings such as cloud functions, container execution api's, or even Kubernetes variations. By design, they are not turn-key offerings. Cyvive , however, is. As an operational platform, it directly interfaces with the cloud provider (or Bare Metal) of choice using the provides IaaS interactions to provision an immutable collection of components necessary to run the orchestrator of choice. The default being Kubernetes","title":"Immutable Operational Platform"},{"location":"#governance","text":"MicroServices are a suite of applications providing a specific function. They are also a key part of Cloud Native architecture, and while there are many benefits to adopting this model over alternatives such as OSIMM / TOSCA. Orchestration Management alone is insufficient and inefficient to managing complex deployments as each has independent release cycles. The defacto approach to MicroServices is to run them within a container, in most situations, even the functions / serverless approach ultimately runs within a container. As such to actually execute the code, open source and propriatory libraries (which are regularly updated) are aggregated into the container, where to comply with security and zero day vulnerability patching must be updated regularly. Ironically, 50 MicroServices are often the tipping point for unmanagable complexity. 50 MicroServices can have a maximum of 1225 interactions, versions, and dependencies between eachother. It is also a realistic expectation that at least one of the Open Source libraries used in each MicroService will need to be updated, tested and validated as production safe every couple of days. Potentially 700 redeploys a month. While the Continous Integration System may validate the code is safe, by nature MicroServices require Continous Deployment / Promotion through environmental complexity to proove they are production stable. MicroServices also have their own independent dependency graph, so actual deployments may not be as simple as replacing a single service in isolation each time. Cyvive , as the Premier MicroService Governance solution, streamlines all complexities through dynamic dependency graphs, an industry standard configuration communication syntax, release management, configuration and version management for MicroServices through to Infrastructure. Any part of your infrastructure can be deployed on-demand, with all relevant dependent services, in any environment.","title":"Governance"},{"location":"#ecosystem","text":"Cloud Native requires a collection of tools, or an extended ecosystem of services to understand and, unlock and leverage its full potential. Each tool, when selected by companies typically goes through a process, that takes months for an efficient team with multitudes of Proof of Concepts, each potentially causing back to the drawing board moments . The modern company doesn't have the luxury of time to assess, stabilize and incrementally add each component of the Cloud Native ecosystem while guaranteeing stability amongst change management in their Digital Transformation journey. Cyvive takes the best in breed tool for each part of the EcoSystem and manages its lifecycle. Choices are available between Open Source or Propriatory where possible. Such careful selection and management of the Best in Breed Candidates of the EcoSystem unlocks the power of the Orchestrator to perform often significantly beyond its standard capabilities","title":"EcoSystem"},{"location":"#cloud-agnostic","text":"It is no longer a realistic expectation that companies can enhance their technology stack by partnering with a single cloud provider. With the growing multitude of high quality cloud providers, each offering niche tools a multi-cloud strategy is a necessity. Cyvive 's detailed Governance and Operational Capabilities allow rapid movement of workloads between cloud providers at an unprecidented scale. It is now a realistic expectation that every hour your entire company can be migrated between clouds based on lowest instance pricing. Without disruption of service.","title":"Cloud Agnostic"},{"location":"#how","text":"We worked with 3 Universities, and over 35 industry publications to analyse trends and approaches to modelling, scaling, interacting and managing MicroService deployents at diabolical scale. The result is the core configuration language of Cyvive , a direct extension of natural descriptive language used in companies today. We also cross partnered to understand and explore each part of the Cloud Native EcoSystem to architect and craft a well-balanced blend of services capable of supporting over 2,500 nodes with 500 containers each. (Yes, Cyvive has been applied to managing over 1 million containers) We pushed immutability down to the operating system, every machine self registers, and is managed exclusively by Cyvive . There is no human access available to the actual machine. Making Cyvive inaccessible to human error. While Cyvive is orchestrator independent, it has been actively used with Kubernetes since version 1.6.x (March 2017) Finally, we selected Terraform for cloud provider bare metal interactions. Properly tuned, full immutable lifecyle management was possible while leveraging all the important functionalities of major cloud providers.","title":"How?"},{"location":"#where","text":"All Major Public Clouds AMD64 / ARM64 Chipsets Bare Metal ( Cyvive creates its own cloud on metal) Cyvive : The Premier Cloud Agnostic Operation Governance Platform","title":"Where?"},{"location":"ecosystem/","text":"In Relation to Cloud Native Cloud Native Computing Foundaton (CNCF) maintains an up to date interactive landscape of applications that are providing some functionality within the five layer scope of Cloud Native Architecture. Kubernetes, being a graduate project of CNCF contains significant modularization capabilities. Some are even expected to be provided externally (i.e. Networking and Monitoring). Cyvive doesn't exist in isolation. As part of extending and optimizing Kubernetes, assessments are carefully undertaken to identify 'Best In Breed' candidates for replacement of standard Kubernetes components, or extensions. While the preference is to utilize 'Best In Breed' from CNCF Landscape and wider industry this is not always possible. And as most are aware, 'Best In Breed' solutions change over time. As such Cyvive maintains a this record of our current 'Best In Breed' suggestions to include in Cyvive's suggested EcoSystem. Mandatory or Optional Each part of the EcoSystem is what we believe to be a 'Best In Breed' recommendation or suggestion. They are exactly that, optional components that can be included or excluded at installation and upgrade time. Cyvive at this time doesn't offer bundle pricing, so selection to install a propriatory EcoSystem part would incur costs between you and the provider directly. The EcoSystem exists because each part offers significant benefit to process, administration, understanding or acceleration of the software management lifecycle. As such, its typically a good idea to include as much of it as possible when using Cyvive Additionally, as Cyvive 's recommendations change over time the installer or upgrader scans your cluster for an older recommendation prior to implementing a new one and where possible suggests upgrade paths. All recommendations are date stamped as to the last time they were assessed Additional Assessment Information Every Enterprise has different requirements for accepting recommendations from an EcoSystem. As such while we try to maintain a transparent comparison on each page, more in-depth information on specific recommendations is available upon request to paying customers.","title":"Understanding"},{"location":"ecosystem/#in-relation-to-cloud-native","text":"Cloud Native Computing Foundaton (CNCF) maintains an up to date interactive landscape of applications that are providing some functionality within the five layer scope of Cloud Native Architecture. Kubernetes, being a graduate project of CNCF contains significant modularization capabilities. Some are even expected to be provided externally (i.e. Networking and Monitoring). Cyvive doesn't exist in isolation. As part of extending and optimizing Kubernetes, assessments are carefully undertaken to identify 'Best In Breed' candidates for replacement of standard Kubernetes components, or extensions. While the preference is to utilize 'Best In Breed' from CNCF Landscape and wider industry this is not always possible. And as most are aware, 'Best In Breed' solutions change over time. As such Cyvive maintains a this record of our current 'Best In Breed' suggestions to include in Cyvive's suggested EcoSystem.","title":"In Relation to Cloud Native"},{"location":"ecosystem/#mandatory-or-optional","text":"Each part of the EcoSystem is what we believe to be a 'Best In Breed' recommendation or suggestion. They are exactly that, optional components that can be included or excluded at installation and upgrade time. Cyvive at this time doesn't offer bundle pricing, so selection to install a propriatory EcoSystem part would incur costs between you and the provider directly. The EcoSystem exists because each part offers significant benefit to process, administration, understanding or acceleration of the software management lifecycle. As such, its typically a good idea to include as much of it as possible when using Cyvive Additionally, as Cyvive 's recommendations change over time the installer or upgrader scans your cluster for an older recommendation prior to implementing a new one and where possible suggests upgrade paths. All recommendations are date stamped as to the last time they were assessed","title":"Mandatory or Optional"},{"location":"ecosystem/#additional-assessment-information","text":"Every Enterprise has different requirements for accepting recommendations from an EcoSystem. As such while we try to maintain a transparent comparison on each page, more in-depth information on specific recommendations is available upon request to paying customers.","title":"Additional Assessment Information"},{"location":"governance/","text":"In Relation to Cloud Native Cloud Native Computing Foundaton (CNCF) 's Orchestration Management and Application Definition or Development layers are places Kubernetes excells, but Kubernetes itself has over 50 core API's and 400+ extended API's cleverly abstracted away via Yet Another Markup Language (YAML) configuration files. For those who have used Kubernetes since the early days, there is an ingrained industry expectation that Minor revisions may contain breaking changes requiring YAML files to be updated. Especially as Beta interfaces transition to Stable. The development speed of Kubernetes ultimately means that each quarterly release requires an audit and management process of YAML files for all Kubernetes API's currently in use by the Enterprise. Such an Audit, is not a small process and often items that should be upgraded are delayed until next release when the old endpoints depreciate and previously working YAML files break. Why Governance? For a detailed understanding of why Governance (service composition) re-surfaced in MicroService architecture see the companion page The Case For Governance Cyvive has, since Kubernetes 1.6.x (September 2016) offered the premier Governance Solution. In March 2017 this Universal MicroServices Language was created via partnership with 3 Universities, and over 35 industry publications. It is the most comprehensive and universalized approach to Governance offered to date. For the first time, developers can stop trying to describe what operations needs from them and align with the core business approaches of: ask for what you need show what your provide MicroService Composition As MicroServices exist in Suites, its a frequent scenario that multiple MicroServices need to be updated in parallel, ensuring correct composition and assessing the total impact of services using existing API's can be a daunting task. Cyvive uses a Machine Learning technique of Prioritized / Force Directed Graphs to identify and assess dependencies between deployed MicroServices. When combined with the Emerging GitOps standard to Continous Integraton, creating a new branch creates a new development namespace with all essential MicroServices deployed. Development now happens directly against real copies of production MicroServices, and multiple can be worked on simultaneously as part of the same GitOps Branch. Additionally, as Cyvive determines the order of prioritization, MicroServices are now able to be deployed rapidly layer by layer ensuring dependent services are available before the next service is deployed. Configuration Secrets Versioning While 12Factor specifies that application configuration should be entirely through Environmental Variables, their population must be managed. In an Agnostic Cloud view, the safest place for configuration management is in Git as part of the emerging GitOps approach. Cyvive builds on this approach, by utilizing Zero Trust Secrets, and tiers of Configuration Management. Whenever a change happens to the original Git repository, Cyvive versions the new configuration and manages its promotion through the cluster, incrementally rolling it out until prooven that the new configuration is safe for production consumption. Environment Management Every Enterprise has several environment types. With the benefit of Kubernetes the prior physical environments are now logical via NameSpaces. But environmental permutations are also simpler increasing risk that environments may drift from their desired configuration. Cyvive has four Core Operating Environment Technology Descriptors: development high availability performance production Any number of NameSpaces can be populated from these core descriptors, each maintaning independent versioning and state of currently deployed applications additionally respecting MicroService Composition, configuration and secret versions. Additionally configuration follows a prioritization based approach where configuration can be overriden and inherited as required: Environment Suite / Group MicroService Function Production Stability This Universal MicroService Language enables an unprecidented portability and co-ordination between Kubernetes clusters and workloads. It also, by default enables Continous Deployment / Promotion where each container is now a production candidate pushed through more complex environments until proven safe to run in production. Cyvive utilises Shadow Traffic Replication between the Production and Performance (names able to be changed to match internal standards) environments as the final validation of application stability. Additionally, this flexibility allows Cyvive to be Cloud Agnostic, in that Premptive Instances can be effectively used for scaling workloads and indeed the entire company's infrastructure can be migrated to whichever public cloud provides the best price for the current hour of Premptive Instance lease. When an architecture is introduced, its necessary for governance to also co-habitiate to ensure that the software solutions within an organization adhere to the defined policies, guidelines, and standards that are defined as a function of the objectives, strategies, and regulations applied in the organization. Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate.","title":"Understanding"},{"location":"governance/#in-relation-to-cloud-native","text":"Cloud Native Computing Foundaton (CNCF) 's Orchestration Management and Application Definition or Development layers are places Kubernetes excells, but Kubernetes itself has over 50 core API's and 400+ extended API's cleverly abstracted away via Yet Another Markup Language (YAML) configuration files. For those who have used Kubernetes since the early days, there is an ingrained industry expectation that Minor revisions may contain breaking changes requiring YAML files to be updated. Especially as Beta interfaces transition to Stable. The development speed of Kubernetes ultimately means that each quarterly release requires an audit and management process of YAML files for all Kubernetes API's currently in use by the Enterprise. Such an Audit, is not a small process and often items that should be upgraded are delayed until next release when the old endpoints depreciate and previously working YAML files break.","title":"In Relation to Cloud Native"},{"location":"governance/#why-governance","text":"For a detailed understanding of why Governance (service composition) re-surfaced in MicroService architecture see the companion page The Case For Governance Cyvive has, since Kubernetes 1.6.x (September 2016) offered the premier Governance Solution. In March 2017 this Universal MicroServices Language was created via partnership with 3 Universities, and over 35 industry publications. It is the most comprehensive and universalized approach to Governance offered to date. For the first time, developers can stop trying to describe what operations needs from them and align with the core business approaches of: ask for what you need show what your provide","title":"Why Governance?"},{"location":"governance/#microservice-composition","text":"As MicroServices exist in Suites, its a frequent scenario that multiple MicroServices need to be updated in parallel, ensuring correct composition and assessing the total impact of services using existing API's can be a daunting task. Cyvive uses a Machine Learning technique of Prioritized / Force Directed Graphs to identify and assess dependencies between deployed MicroServices. When combined with the Emerging GitOps standard to Continous Integraton, creating a new branch creates a new development namespace with all essential MicroServices deployed. Development now happens directly against real copies of production MicroServices, and multiple can be worked on simultaneously as part of the same GitOps Branch. Additionally, as Cyvive determines the order of prioritization, MicroServices are now able to be deployed rapidly layer by layer ensuring dependent services are available before the next service is deployed.","title":"MicroService Composition"},{"location":"governance/#configuration-secrets-versioning","text":"While 12Factor specifies that application configuration should be entirely through Environmental Variables, their population must be managed. In an Agnostic Cloud view, the safest place for configuration management is in Git as part of the emerging GitOps approach. Cyvive builds on this approach, by utilizing Zero Trust Secrets, and tiers of Configuration Management. Whenever a change happens to the original Git repository, Cyvive versions the new configuration and manages its promotion through the cluster, incrementally rolling it out until prooven that the new configuration is safe for production consumption.","title":"Configuration &amp; Secrets Versioning"},{"location":"governance/#environment-management","text":"Every Enterprise has several environment types. With the benefit of Kubernetes the prior physical environments are now logical via NameSpaces. But environmental permutations are also simpler increasing risk that environments may drift from their desired configuration. Cyvive has four Core Operating Environment Technology Descriptors: development high availability performance production Any number of NameSpaces can be populated from these core descriptors, each maintaning independent versioning and state of currently deployed applications additionally respecting MicroService Composition, configuration and secret versions. Additionally configuration follows a prioritization based approach where configuration can be overriden and inherited as required: Environment Suite / Group MicroService Function","title":"Environment Management"},{"location":"governance/#production-stability","text":"This Universal MicroService Language enables an unprecidented portability and co-ordination between Kubernetes clusters and workloads. It also, by default enables Continous Deployment / Promotion where each container is now a production candidate pushed through more complex environments until proven safe to run in production. Cyvive utilises Shadow Traffic Replication between the Production and Performance (names able to be changed to match internal standards) environments as the final validation of application stability. Additionally, this flexibility allows Cyvive to be Cloud Agnostic, in that Premptive Instances can be effectively used for scaling workloads and indeed the entire company's infrastructure can be migrated to whichever public cloud provides the best price for the current hour of Premptive Instance lease. When an architecture is introduced, its necessary for governance to also co-habitiate to ensure that the software solutions within an organization adhere to the defined policies, guidelines, and standards that are defined as a function of the objectives, strategies, and regulations applied in the organization. Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate.","title":"Production Stability"},{"location":"governance/case-for/","text":"Global Scene Today Applications have been transitioning from a Monolithic approach to Service Oriented for a number of years, and while different languages offered alternate approaches and standards such as 12Factor and OSIMMv2 started to emerge as to best practices for managing MicroService and Service Oriented applications (SOA). The disruption of containerization and more specifically Docker resulted in a mass exodus from more traditional architectural approaches towards Cloud Native Architecture. After the advent of Docker it became rapidly apparent that MicroService centric technology and stateful workloads had challenges in organizational implementation. Specifically around the areas of scheduling and persistent storage. To further complicate the scene developers were expected to understand how linux operating systems work from a process 1 layer and become specialists in system administration and orchestration of Highly Available applications overnight. What typically resulted (and still does) is a multitude of containers running MicroServices assembled in various pet environment and machines. In need of traditional infrastructure architecture and external services such as Layer 4/7 LoadBalancers to and Cloud Interfaces to ensure the MicroServices run acceptably. To achieve this the concept of Container Orchestration was created where the landscape rapidly consolidated into a single orchestrator and cloud provider. Kubernetes carrying the additional advantage of being cable of abstracting the underlying infrastructure cloud services and provisioning away from the MicroService interactions and scope. As of today, Kubernetes has 400+ API endpoints, with 50+ core. It rolls out breaking releases every quarter and aggressively removes depreciated API endpoints to keep its complexity lighter. Its an excellent and highly resilient technology, but requires organizations to keep up with its release cycle to ensure a happy path for all co-existent tooling. Cloud Native Computing Foundation has been created to assist in ensuring key extensions / installers and components of Kubernetes stay current and functioning. Kubernetes also abstracts the concept of physical environments into a logical layer. An excellent approach to creating multiple test or production environments on demand, with default settings that can also be isolated at via network from eachother. The Challenge Ideally MicroServices should be able to be deployed independently of eachother, live separate life cycles and handle dependencies sanely. In reality there are always dependencies, even if the primary dependency is on a stateful storage interface or broker if following the MicroService Saga pattern. Additional complexity is also realised that MicroServices in Enterprise Environments provide more of a Cloud Friendly / Native approach but still follow similar pricinciples of TOGAF / OSIMMv2. OSIMMv2 - MicroServices: Service - Suite of MicroServices Component - MicroService Sub-Component - Function Decomposition typically falls to Business Units which in turn typically offer a collection of Services (Suites of MicroServices) for consumption by customers or other Business Units within the same company. Ironically, 50 MicroServices are often the tipping point for unmanagable complexity. 50 MicroServices can have a maximum of 1225 interactions, versions, and dependencies between eachother. It is also a realistic expectation that at least one of the Open Source libraries used in each MicroService will need to be updated, tested and validated as production safe every couple of days. Potentially 700 redeploys a month. To further complicate the process and management of MicroServices the industry expectation is that the MicroService should understand its own limits and requirements for appropriate scheduling and scaling out when under load. Thus each MicroService should be performance tested with each release. Immediately causing the need for versioning of MicroService configuration, and the ability to progressively manage the configuration in environments that the MicroService has or will be deployed in. In a nutshell the challenges plaguing MicroServices are: versioned configuration management versioned secrets management dependencies on other MicroServices Infrastructure requirements and resourcing Governance Re-surfacing In traditional Application Lifecycle pre-revolution the infrastructure requirements would have been handled by a Governance layer, describing exactly what Infrastructure, configuration, performance and resources the application would have needed. In the container world, the closest functional alternative has been Docker Compose, quickly failing to be effective when operating on multiple machines or preserving environment secrets for application consumption. Rancher , following in the footsteps of Panamax also tried to provide a light weight governance and dependency management approach through a service catalogue, but this is only useful for initial deployments of applications into environments and forces a hard externally managed blue / green deployment approach which is not enterprise friendly or startup safe. The issue most approaches share is they come from the infrastructure and orchestration approach, which ultimately makes sense as infrastructure is what the orchestration is providing the MicroService. Unfortunately becoming a part-time system admin is not what most developers aspire to, and they quickly find the orchestrator over-complex for their needs while in reality it may not be complex enough. Fortunately, Cyvive worked with 3 Universities, and over 35 industry publications to analyse trends and approaches to modelling, scaling, interacting and managing MicroService deployents at diabolical scale. The result is the core configuration language of Cyvive , a direct extension of natural descriptive language used in companies today. This Universal MicroService Language allows abstraction of the complexity of orchestration, management and infrastructure away from DevSecOps, while opening up communication between business, encompasing current and future development. As such, a Suite of MicroServices; MicroService; or Function can all share the same descriptive language, and that meta-language can consistently hold through each advancement of containerization or orchestration irrespective of the underlying complexity of interface. This ironically, is Governance revised and re-applied in a methodology that integrates with existing systems of communication and development cycles. Alternative non-Governed Kubernetes Approaches Fundamentally fall into the following categories: Template Driven The approach used by this collection is to focus on desired end-state while stripping out the technical implementation detail. They use template languages such as TOML, GOTemplate, Jinja2 and others to achieve this. The most well known of all these is Helm which ironically labels and describes itself as a package manager built on templates. It extends the Kubernetes API and requires additional security settings to be enabled in the cluster to operate safely and effectively. The major challenge with this approach is that its strength lies in user submitted packages being crafted correctly with enough configuration options to be relevant. So while it appears to save time for initial deployment of some MicroServices most organizations end up re-writing large portions of existing templates or maintaining their own with an abstraction layer. Additionally its not upgrade safe, as the Kubernetes endpoints regularly migrate and configuration will need to be actively maintained and assessed for all applications every quarter. Additionally, exact versioning matching against the MicroService can be challenging as the template approach works best with a central repository / server with configuration outside the MicroService repository The irony of the template approach is that while it appears to be simpler, it actually requires a deeper understanding of the orchestration technology than most developers would need in their day to day work as all moving template parts are necessary to be learnt in depth. Typically this approach is used when a central team owns and maintains all templates along with the orchestration platform (Kubernetes) Some template approaches go as far as defining an entire programming language to build upon. CI/CD extensions A common emerging pattern is to extend the CI/CD tool with the bare minimum information to achieve a successful Kubernetes deployment. Then when the version deployed is changed by the CI/CD process the existing deployment is rolled forward / patched. While in principle this approach seems an easy win, it suffers from many of the same challenges as the Template Approach in that the deployment templates become outdated and need to be reviewed every quarter. It requires specialist knowledge and often heavy repetition between MicroServices in detailing their configuration which is prone to mistakes, and there is no standardization between MicroServices in naming of configuration. Additionally secrets and configuration become challenging when wanting to abstract away from or share between MicroServices at a business unit level. Developer Assistance A continually shifting landscape of tools, some offer benefit for a variable period of time, but most are created to scratch their own itch in a sense. The trend in this space is to remove the CI/CD pipeline entirely by building the container on the local machine, and abstract a development environment directly against the local Docker Daemon typically based on Docker Compose. Lots of innovation, but nothing that accelerates development in a solid way that's well maintained and sustainable for multiple languages. These also bleed into baseline libraries for MicroService development where they can force developer to implement Cloud Native approaches in their MicroServices such as sharding and synchronization locks. The main benefit is that interaction with the orchestration tooling can happen from the same language as the developer is working in, but as the cost of integration and visibility of more complex Services. i.e. works well in isolation Alternative Non-Kubernetes Approaches Are focused on extending infrastructure tools such as CHEF and PUPPET to interface nostalgically with an orchestration technology. While these tools are excellent for those with a deep infrastructure background, they have never historically been picked up well by developers who when forced down this route prefer to use the orchestration technology directly over the infrastructure tooling.","title":"Case for Governance"},{"location":"governance/case-for/#global-scene-today","text":"Applications have been transitioning from a Monolithic approach to Service Oriented for a number of years, and while different languages offered alternate approaches and standards such as 12Factor and OSIMMv2 started to emerge as to best practices for managing MicroService and Service Oriented applications (SOA). The disruption of containerization and more specifically Docker resulted in a mass exodus from more traditional architectural approaches towards Cloud Native Architecture. After the advent of Docker it became rapidly apparent that MicroService centric technology and stateful workloads had challenges in organizational implementation. Specifically around the areas of scheduling and persistent storage. To further complicate the scene developers were expected to understand how linux operating systems work from a process 1 layer and become specialists in system administration and orchestration of Highly Available applications overnight. What typically resulted (and still does) is a multitude of containers running MicroServices assembled in various pet environment and machines. In need of traditional infrastructure architecture and external services such as Layer 4/7 LoadBalancers to and Cloud Interfaces to ensure the MicroServices run acceptably. To achieve this the concept of Container Orchestration was created where the landscape rapidly consolidated into a single orchestrator and cloud provider. Kubernetes carrying the additional advantage of being cable of abstracting the underlying infrastructure cloud services and provisioning away from the MicroService interactions and scope. As of today, Kubernetes has 400+ API endpoints, with 50+ core. It rolls out breaking releases every quarter and aggressively removes depreciated API endpoints to keep its complexity lighter. Its an excellent and highly resilient technology, but requires organizations to keep up with its release cycle to ensure a happy path for all co-existent tooling. Cloud Native Computing Foundation has been created to assist in ensuring key extensions / installers and components of Kubernetes stay current and functioning. Kubernetes also abstracts the concept of physical environments into a logical layer. An excellent approach to creating multiple test or production environments on demand, with default settings that can also be isolated at via network from eachother.","title":"Global Scene Today"},{"location":"governance/case-for/#the-challenge","text":"Ideally MicroServices should be able to be deployed independently of eachother, live separate life cycles and handle dependencies sanely. In reality there are always dependencies, even if the primary dependency is on a stateful storage interface or broker if following the MicroService Saga pattern. Additional complexity is also realised that MicroServices in Enterprise Environments provide more of a Cloud Friendly / Native approach but still follow similar pricinciples of TOGAF / OSIMMv2. OSIMMv2 - MicroServices: Service - Suite of MicroServices Component - MicroService Sub-Component - Function Decomposition typically falls to Business Units which in turn typically offer a collection of Services (Suites of MicroServices) for consumption by customers or other Business Units within the same company. Ironically, 50 MicroServices are often the tipping point for unmanagable complexity. 50 MicroServices can have a maximum of 1225 interactions, versions, and dependencies between eachother. It is also a realistic expectation that at least one of the Open Source libraries used in each MicroService will need to be updated, tested and validated as production safe every couple of days. Potentially 700 redeploys a month. To further complicate the process and management of MicroServices the industry expectation is that the MicroService should understand its own limits and requirements for appropriate scheduling and scaling out when under load. Thus each MicroService should be performance tested with each release. Immediately causing the need for versioning of MicroService configuration, and the ability to progressively manage the configuration in environments that the MicroService has or will be deployed in. In a nutshell the challenges plaguing MicroServices are: versioned configuration management versioned secrets management dependencies on other MicroServices Infrastructure requirements and resourcing","title":"The Challenge"},{"location":"governance/case-for/#governance-re-surfacing","text":"In traditional Application Lifecycle pre-revolution the infrastructure requirements would have been handled by a Governance layer, describing exactly what Infrastructure, configuration, performance and resources the application would have needed. In the container world, the closest functional alternative has been Docker Compose, quickly failing to be effective when operating on multiple machines or preserving environment secrets for application consumption. Rancher , following in the footsteps of Panamax also tried to provide a light weight governance and dependency management approach through a service catalogue, but this is only useful for initial deployments of applications into environments and forces a hard externally managed blue / green deployment approach which is not enterprise friendly or startup safe. The issue most approaches share is they come from the infrastructure and orchestration approach, which ultimately makes sense as infrastructure is what the orchestration is providing the MicroService. Unfortunately becoming a part-time system admin is not what most developers aspire to, and they quickly find the orchestrator over-complex for their needs while in reality it may not be complex enough. Fortunately, Cyvive worked with 3 Universities, and over 35 industry publications to analyse trends and approaches to modelling, scaling, interacting and managing MicroService deployents at diabolical scale. The result is the core configuration language of Cyvive , a direct extension of natural descriptive language used in companies today. This Universal MicroService Language allows abstraction of the complexity of orchestration, management and infrastructure away from DevSecOps, while opening up communication between business, encompasing current and future development. As such, a Suite of MicroServices; MicroService; or Function can all share the same descriptive language, and that meta-language can consistently hold through each advancement of containerization or orchestration irrespective of the underlying complexity of interface. This ironically, is Governance revised and re-applied in a methodology that integrates with existing systems of communication and development cycles.","title":"Governance Re-surfacing"},{"location":"governance/case-for/#alternative-non-governed-kubernetes-approaches","text":"Fundamentally fall into the following categories:","title":"Alternative non-Governed Kubernetes Approaches"},{"location":"governance/case-for/#template-driven","text":"The approach used by this collection is to focus on desired end-state while stripping out the technical implementation detail. They use template languages such as TOML, GOTemplate, Jinja2 and others to achieve this. The most well known of all these is Helm which ironically labels and describes itself as a package manager built on templates. It extends the Kubernetes API and requires additional security settings to be enabled in the cluster to operate safely and effectively. The major challenge with this approach is that its strength lies in user submitted packages being crafted correctly with enough configuration options to be relevant. So while it appears to save time for initial deployment of some MicroServices most organizations end up re-writing large portions of existing templates or maintaining their own with an abstraction layer. Additionally its not upgrade safe, as the Kubernetes endpoints regularly migrate and configuration will need to be actively maintained and assessed for all applications every quarter. Additionally, exact versioning matching against the MicroService can be challenging as the template approach works best with a central repository / server with configuration outside the MicroService repository The irony of the template approach is that while it appears to be simpler, it actually requires a deeper understanding of the orchestration technology than most developers would need in their day to day work as all moving template parts are necessary to be learnt in depth. Typically this approach is used when a central team owns and maintains all templates along with the orchestration platform (Kubernetes) Some template approaches go as far as defining an entire programming language to build upon.","title":"Template Driven"},{"location":"governance/case-for/#cicd-extensions","text":"A common emerging pattern is to extend the CI/CD tool with the bare minimum information to achieve a successful Kubernetes deployment. Then when the version deployed is changed by the CI/CD process the existing deployment is rolled forward / patched. While in principle this approach seems an easy win, it suffers from many of the same challenges as the Template Approach in that the deployment templates become outdated and need to be reviewed every quarter. It requires specialist knowledge and often heavy repetition between MicroServices in detailing their configuration which is prone to mistakes, and there is no standardization between MicroServices in naming of configuration. Additionally secrets and configuration become challenging when wanting to abstract away from or share between MicroServices at a business unit level.","title":"CI/CD extensions"},{"location":"governance/case-for/#developer-assistance","text":"A continually shifting landscape of tools, some offer benefit for a variable period of time, but most are created to scratch their own itch in a sense. The trend in this space is to remove the CI/CD pipeline entirely by building the container on the local machine, and abstract a development environment directly against the local Docker Daemon typically based on Docker Compose. Lots of innovation, but nothing that accelerates development in a solid way that's well maintained and sustainable for multiple languages. These also bleed into baseline libraries for MicroService development where they can force developer to implement Cloud Native approaches in their MicroServices such as sharding and synchronization locks. The main benefit is that interaction with the orchestration tooling can happen from the same language as the developer is working in, but as the cost of integration and visibility of more complex Services. i.e. works well in isolation","title":"Developer Assistance"},{"location":"governance/case-for/#alternative-non-kubernetes-approaches","text":"Are focused on extending infrastructure tools such as CHEF and PUPPET to interface nostalgically with an orchestration technology. While these tools are excellent for those with a deep infrastructure background, they have never historically been picked up well by developers who when forced down this route prefer to use the orchestration technology directly over the infrastructure tooling.","title":"Alternative Non-Kubernetes Approaches"},{"location":"governance/installing/","text":"Installing Cyvive.io Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Requirements Compatible backend container orchestrator such as Kubernetes Cluster Administrator access Firewall access to containers stored on 'Google Container Registry' (This should already be enabled in most cluster orchestration setups) What Occurs In Cluster \u2026 will have slight variations in execution based on the selected orchestration backend, but the end interaction process is the same. Cyvive.io is installed in the system namespace an internal endpoint is created for access a 'httpie' container is created for simplified manual interaction with Cyvive.io a configMap is created to store Cyvive.io 's database information. Kubernetes Installation \u2026 is conducted via kubectl, and has been simplified down to a single command. {KubernetesVersion} should be replaced with 'v1.8' or the Major Minor Version of your cluster kubectl apply -f https://raw.githubusercontent.com/TayloredTechnology/www.cyvive.io/master/docs/deploy/kubernetes/v1.8/cyvive.yaml Note Cyvive.io is perfectly suitable to run within a 'MiniKube' environment Interacting with HTTPIE Pod export HTTP_POD=$(kubectl get pods -n kube-system -l cyvive=httpie -o name | cut -d / -f2) kubectl exec -ti -n kube-system ${HTTP_POD} bash HTTPIE Instructions can be helpful for first timers, naturally any REST compatible tool would be suitable. For example to create a deploymentTarget for all applications / services governed by Cyvive.io http POST cyvive:3000/namespace deploymentTarget=development template=dev Next Steps \u2026 vary in complexity depending on the role inhabited within the organisation Governance - Cluster - Organizational Developer","title":"Installing _Cyvive.io_"},{"location":"governance/installing/#installing-cyviveio","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate.","title":"Installing Cyvive.io"},{"location":"governance/installing/#requirements","text":"Compatible backend container orchestrator such as Kubernetes Cluster Administrator access Firewall access to containers stored on 'Google Container Registry' (This should already be enabled in most cluster orchestration setups)","title":"Requirements"},{"location":"governance/installing/#what-occurs-in-cluster","text":"\u2026 will have slight variations in execution based on the selected orchestration backend, but the end interaction process is the same. Cyvive.io is installed in the system namespace an internal endpoint is created for access a 'httpie' container is created for simplified manual interaction with Cyvive.io a configMap is created to store Cyvive.io 's database information.","title":"What Occurs In Cluster"},{"location":"governance/installing/#kubernetes-installation","text":"\u2026 is conducted via kubectl, and has been simplified down to a single command. {KubernetesVersion} should be replaced with 'v1.8' or the Major Minor Version of your cluster kubectl apply -f https://raw.githubusercontent.com/TayloredTechnology/www.cyvive.io/master/docs/deploy/kubernetes/v1.8/cyvive.yaml Note Cyvive.io is perfectly suitable to run within a 'MiniKube' environment","title":"Kubernetes Installation"},{"location":"governance/installing/#interacting-with-httpie-pod","text":"export HTTP_POD=$(kubectl get pods -n kube-system -l cyvive=httpie -o name | cut -d / -f2) kubectl exec -ti -n kube-system ${HTTP_POD} bash HTTPIE Instructions can be helpful for first timers, naturally any REST compatible tool would be suitable. For example to create a deploymentTarget for all applications / services governed by Cyvive.io http POST cyvive:3000/namespace deploymentTarget=development template=dev","title":"Interacting with HTTPIE Pod"},{"location":"governance/installing/#next-steps","text":"\u2026 vary in complexity depending on the role inhabited within the organisation Governance - Cluster - Organizational Developer","title":"Next Steps"},{"location":"governance/configuration/","text":"Micro/NanoService YAML Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Info Scope: MicroService Specific File: cyvive.yaml Location: Git Repository / CI/CD Pushed Understanding \u2026 core component of the Universal MicroServices Language . This file describes the specific MicroService Governance policy to be extracted and implemented on demand in a Cloud Agnostic Cluster. While Cyvive doesn't mandate a specific adoption approach, a truely minimal configuration file is achieved through following industry best practices for structure and oragnisation. Cyvive 's configuration language is architecturally and contexturally derived from partnership with 3 Universities and over 35 industry publications for providing a governance via policy meta-model that agnostically interfaces with the most complex orchestration technology while articulately able to be used in conversation. This file is a powerhouse behind agnostic infrastructure, and provides the most simple abstraction of deployment available today. Naming Cyvive aligns with Cloud Native and MicroServices approaches. However, this Universal MicroServices Language is flexible enough to be used with OSIMMv2 / TOGAF as such the following naming conventions apply: MicroServices : - Suite - Micro - Nano OSIMMv2 / TOGAF - Group - Suite - Service - Micro - Component - Nano CloudFunctions - Functions - Nano If your PaaS can efficiently start instances in 20ms that run for half a second, then call it serverless Adrian Cockcroft AWS VP - 2016 In the context of this quote, any well designed container with proper governance and management can be classified as a function . For this reason, Cyvive uses the terminology Nano instead of function to more appropriately cover the functions and nanoservices classifications. Absolute Minimum File Structure Note '\u21db' character is used throughout this documentation where items are mandatory with respect to the parent YAML key. If not specified, then item is optional. exampleSuite: \u21db exampleMicro: \u21db version: v1.8.x \u2026 this minimum structure is all that is necessary for Cyvive to commence governance and interface with the orchestration technology at a minimum level. If Cyvive was then used to govern this application / service in a deploymentTarget called 'preproduction' using the template 'perf' against Kubernetes as a orchestrator the following would happen: a Deployment would be created using the DockerHub hosted image: exampleSuite/exampleMicro:v1.8.x a Service would be created mapping port 80 to the Deployment a DNS entry would be created in the cluster as exampleMicro.exampleSuite.preproduction.svc.cluster.local any other applications governed by Cyvive 's and allowed to be deployed against this template would also be deployed following an automated dependency order. Note SemVer is rapidly becoming the version management approach of choice for development as it balances the needs of devoplers and continous container deployment well while maintaining business requirements for release management and change requests. Micro/NanoService Inheritence Structure exampleSuite: \u21db exampleMicro: nano: identifier \u21db version: vTag \u2026 the typical structure used in a governance model would provide nano , micro , suite as units of categorization. Cyvive inherits this concept where typically suite would be a higher level Business Unit correctly decomposed containing a collection of MicroServices . The splitting point between micro and nano typically has a line of demarkation drawn between the need for an internal data model and direct algorithmic processing. The exact definition and demarkation of suites is left to the client, however by default when requesting a container from the container repository the format will be as such: - exampleSuite/exampleMicro:vTag or - exampleSuite/exampleMicro-exampleNano:vTag if nano key has been provided As such its possible to use Cyvive with any level of complexity in application relationships, while keeping isolation and deployment in a layered security approach. Suite Level Configuration / Technology Descriptor exampleSuite exampleMicro: {} suite: {} \u2026 is available for all suites under governance. Where applicable identical specifications at the suite level override the template level. Its not necessary for suite information to be specified as a pre-requisite to adding a Micro/NanoService. It is possible for a Micro/NanoService to inherit configuration information from the suite level, thus allowing enhanced security over a traditional deployment model, where keys can be present in the application environment and unknown to developers with MicroService / NanoService source code access. Additional information on the suite Technology Descriptors is available MicroService Technology Descriptor exampleSuite exampleMicro: availability: {} circuitBreaker: {} commandLineInterface: {} component: string daemon: boolean endpoint: {} environment: {} label: {} layer: string repository: {} resource: {} security: {} stateful: {} version: {} \u2026 illustrates a high level overview of the logical configuration sections. Detailed information is located under each subheading below. Where values for keys are shown they are the default values. availability exampleSuite: exampleMicro: availability: gracePeriod: boot: 1 stability: 0 termination: 5 minimum: 1 maximum: 2 probe: health: interval: 10 path: / port: 80 ready: interval: 5 path: / port: 80 timeout: 1 scalingEvent: {} gracePeriod : minimum time in seconds to wait for events to occur boot : Micro/NanoService operating system startup boot time, this should be the minimum time before a health check endpoint is available to process a request. stability : amount of time to wait for the health check endpoint to ensure consistent returns after boot time has been completed. This is typically used in legacy applications that need to stabilize their upstream and downstream communications when started or have large amounts of data to sync. termination : is the maximum amount of time to wait before hard terminating the container operating system. It does not guarantee the Micro/NanoService will have or take this long to terminate, its just the maximum amount of time to wait for the signal from the container operating system to ensure its okay to terminate. (Note: the termination signal is sent immediately to all container processes, this is the period before the kill signal is sent) minimum : guaranteed minimum number of replicas to always be deployed in the deploymentTarget maximum : when scaling ensure that this number is not exceeded probes : notify the underlying orchestrator of Micro/NanoService status. Where /health is actual health, and /ready is ability to recieve traffic interval : time in seconds for checking endpoint path : endpoint path relative to container port : internal port the probe endpoint is listening on timeout : this option is not nested under each probe as failures are being monitored for, its expected that timeout values should apply to all check related endpoints equally. scalingEvent : is a passthrough object of trigger events to integrate with orchestration support in triggering scaling up and down of the replicas. Note: With respect to deployment timeouts, Cyvive 's standard approach is to stall deployments as failed if the Micro/NanoService fails to enter ready state using one of the following timelines in order of priority rounded to the nearest second: probe.ready specified: (gracePeriod.boot + gracePeriod.stability + (probe.ready.interval * 2)) * 3.3 probe.health specified: (gracePeriod.boot + gracePeriod.stability + probe.health.interval) * 3.3 gracePeriod.stability : (gracePeriod.boot + gracePeriod.stability + 10) * 3.3 gracePeriod.boot : (gracePeriod.boot + 10) * 3.3 default settings : 33 seconds As seen above 10% buffer is applied to times to ensure container schedulling / restarting via the orchestrator doesn't introduce false-positives circuitBreaker Info configuration structure still stabilizing commandLineInterface exampleSuite: exampleMicro: commandLineInterface: argument: [] command: \u2026 is an override path for container start commands. While most startups will embed the start command and respective arguments in the container image itself, efficient governance exposes all configuration, execution and dependency information. As such the organisation can choose to embed startup information in the container metadata or expose via governance layer. argument : standard cli arguments for execution. e.g. ['--list', '--debug'] command : root command to execute when starting the container. e.g. '/usr/local/bin/command' should this not be specified then the default command the container was built with will be executed. nano exampleSuite: exampleMicro: nano: \u2026 provides a namespace separation for nano Services. Typically used when the MicroService would need to be logicaly broken down further than is possible within the suite specification. Or when only algorithmic processing capabilities are necessary daemon exampleSuite: exampleMicro: daemon: false \u2026 upgrades the Micro/NanoService to run as a Daemon in the deploymentTarget . This ensures that every physical node belonging to this suite will have this Daemon available on a low-latency local network hop. endpoint exampleSuite: exampleMicro: endpoint: domain: {} port: 80 provide: [ / ] scheme: https require: [] \u2026 are created for every Micro/NanoService by default and register DNS via the following schema: nanoName-microName.suiteName.deploymentTarget.domain port : open port for inbound interaction. provide : important for correct dependency management the provide endpoints are the registration points for Micro/NanoService searching and generation in the deployment graph. scheme : extensible against the scheme definitions in RFC standards, the key types are http and https where specifying https will cause auto-creation of SSL certificates at the cluster ingress point. Exploring the complex root keys: domain: xyz.com : [ DEVLIKE , HALIKE , PRODLIKE ] testing.co : [ DEVLIKE ] The domain object is structured as follows: - key : the domain name to expose against. This should be the Fully Qualified Domain Name ( FQDN ) as autogenerated DNS structure applies inside the cluster only. - value : array of operatingEnvironment 's valid for exposing against. Exposure follows the schema mentioned previously, however it can be overridden as necessary require: - redux.exampleSuite:443/api/v1/ending : [ incoming ] - exampleMicro.exampleSuite:80/v1/ : [ incoming , outgoing ] - 162.0.5.2:8080/ : [ outgoing ] The require object is quite important, and while optional, strongly recommended to always be supplied. It identifies all dependencies this Micro/NanoService has and helps contribute to the deployment order when creating a deploymentTarget . In the event a require is not registered with Cyvive it will be considered external to the cluster and assumed to already exist. A useful note is that different versions of the same Micro/NanoService can be consumed by other eachother. This is achieved via the version key where each governance technology descriptor registers against the Micro/NanoService version. The require object is structured as follows: - key : Uniform Resource Identifier (URI) RFC 3986 compliant. The scheme is unnecessary as any routing restrictions are scoped as above - value : traffic direction for filewall / security registration environment exampleSuite: exampleMicro: environment: file: config: {} secret: {} variable: {} \u2026 all items are directly exposed to the Micro/NanoService. Exploring the complex root keys: files: config: alpha : mountPath: /alpha data: - name: configDetail value: string of information delta : inheritSuite: false Each item in config is a representation of a ConfigMap with individual items specified in the array object under data . Each item represents an individual file. mountPath is the directory location in the container that the ConfigMap should be mounted to. If inheritSuite is provided the configuration will be loaded from the suite settings enabling a more 'global' oriented view of configuration files: secrets: secretname : type: opaque mountPath: /secret-location data: - name: secretInfo value: (base64 string) anothersecret : inheritSuite: false Each item in secrets is a map with individual items under data representing files to be mounted into the mountPath location in the container. If inheritSuite is provided the secret will be loaded from the suite settings enabling a more 'global' oriented view of configuration variable: exposeName : exposeValue Direct mapping of the key to value provided as an environmental variable when executing the container start command. Additionally Cyvive exposes some helper variables to identify the current context of the Micro/NanoService: SELF_NAME : name of the Micro/NanoService. This will also be the hostname of the running container SELF_NAME_LOADBALANCER : to assist in discovery, this is the LoadBalancer endpoint for incluster communication to this container and its replicas. This is relative to the deploymentTarget and not the Fully Qualified Domain Name (FQDN) SELF_DEPLOYMENTTARGET : deploymentTarget that the Micro/NanoService has been deployed into SELF_IP : the internal cluster IP of the container The following self-explanatory variables are also available to the container when specified via Cyvive 's governance: SELF_MIN_MEMORY SELF_MIN_CPU SELF_MAX_MEMORY SELF_MAX_CPU hardWired exampleSuite: exampleMicro: hardWired: clusterDNS: \u2026 is a catch-all for compatibility with non-governed processes. It is strongly recommended not to use these keys unless absolutely necessary as each key will disable some governance functionality and introduce independent manual management scenarios that wouldn't normally be necessary. clusterDNS : is a hard overwrite of the cluster internal load balancer endpoint for the Micro/NanoService. It disables the autogeneration capabilities and can help with initially migrating non Cloud Native items. label exampleSuite: exampleMicro: label: # app: autocompleted ~ appName # component: autocompleted ~ component # release: autocompleted in PRODLIKE environments ~ canary or stable # tier: autocompleted ~ suiteName # version: autocompleted ~ version key {any others you require} Any labels not specified above can be used to help identify the applications services. As the aforeentioned labels are reserved by Cyvive for governance, any custom values provided will be ignored as they are used for asset tracking Although there is nothing stopping its use, the recommended approach is not to use hotfix as a label or blue / green for deploys as when running Micro/NanoServices en masse at scale, canary has been observed repeatedly as a more stable; reduced risk; and governable approach as everything passes through a 'canary' state anyway. (Under candidate based releases hotfixes are just releases that have been accelerated through the canary phase) Additionally, Cyvive uses Shadow Traffic Replication where return values are thrown away to prevent interference with production. This further provides isolation over the standard 'canary' approach validating the safety of the entire ecosystem to promote as a validated whole. There is no limit to how many labels can be specified layer exampleSuite: exampleMicro: layer: base \u2026 is a concept often used in Enterprise Architecture and earlier iterations of MicroServices. Cyvive underwent an extreemly careful active engagement process with its users prior to introducing this key. The layer concept is used as part of the dependency graph generation process. Prioritizing and guaranteeing deployments of each layer prior to commencing the next, failing fast when any layer fails to deploy. Layers in Order 1. data 2. communication 3. cache 4. backend 5. frontend While strictly not necessary to specify, if known the layer should be specified as it allows for accelerated parallel deployment in the desired deploymentTarget repository exampleSuite exampleMicro: repository: image: domain: hub.docker name: exampleRedux officialImage: false owner: exampleRedux \u2026 image registry autogenerated name uses the format: repository/owner/name as such the default without image specified would be one of: - hub.docker/exampleSuite/exampleMicro or - hub.docker/exampleSuite/exampleMicro-exampleNano if nano key has been provided as seen earlier in repository This can be overriden to anything you need in any combination using the following values: domain : overrides suite or template domain settings name : overrides exampleMicro in the sample. This impacts deployed application name container image repository url generation. officialImage : is a structureal specification for DockerHub where official images have a different retrieval structure. Setting this as true would result in exampleMicro being the official image name or if provided name would still override to be the official image name. owner : override for owner in technology descriptor resource exampleSuite: exampleMicro: resource: max: cpu: 500 memory: 1Gi min: cpu: 300 memory: 1Gi qos: \u2026 allocation is an important part of all container orchestration schedullers, and these values should be provided prior to deploying Micro/NanoService to production deploymentTarget although, if not specified Cyvive will operate without issue. max absolute maximum requirements that we are prepared to allocate. min minimum required in order to guarantee application boot and ready for traffic interaction. qos is mandatory should min or max be specified If neither min or max are specified then template defaults (if specified) will be used. The ability to provide template resource defaults is to ensure safe co-habitation of Services / Applications / Components when / if they go rogue. cpu is units of CPU core specified in 'm' thus for a single CPU core 1000 should be used. The 'm' is omitted and should not be specified. memory should always have the multiplier specified as part of the value i.e. 'Gi' any suitable value can be specified from the following: Ki Mi Gi Ti Pi Ei qos follows the approach: guaranteed : highest possible level, everything not this level will suffer 'pause' events to ensure these pods continue to operate. burstable : default min values are allocated to the pod as minimum required to run. No upper limits are placed on resources. effort : can be used when the application is lowest priority of them all. min , max and namespace default values are totally ignored. (Currently un-implemented due to lack of user demand) security Info configuration structure still stabilizing exampleSuite: exampleMicro: security: account: name: alternativeOne reference: admin account : should an account be required that isn't the suite security account or 'default' i.e. another suite's account. It can be overriden here. Specifying will create the account if it doesn't exist stateful Info configuration structure still stabilizing exampleSuite: exampleMicro stateful: cloudNative: false databaseName: individualServices: false replica: 3 sharedStorage: false volume: avolume : mountPath: /avolume size: 10Gi storageClass: cloudNative : Enables the ability to deploy stateful applications in parallel and will automatically compact number of replicas down in envionments that aren't 'HALIKE' or 'PRODLIKE' to save resources. databaseName : standard application naming will be applied if this field is omitted. Its frequently used in custom templates for configuring some of the expected internals individualServices : some applications can operate under a common service endpoint, others such as MongoDB require fixed service endpoints for each database replica : number of PODS that should be deployed, if the backend supports it anti-affinity rules will already be in place per Availablility Zone and Host. sharedStorage : determines if the PODS should have mount the same storage or have unique storage per pod ( warhing multi-mount storage is unsupported by most storage drivers) storageClass : the type of storage strategy that should be applied In providing a consistent minimal configuration the stateful configuration integrates with endpoint and it should be used for accessing accordingly Amount of time that should be given after sending kill signal to the container OS before terminating and removing the container. version exampleSuite: exampleMicro: version: latest \u2026 standards and application is a constantly debated aproach with different internal standards used within organizations. Internally Cyvive maintains governance versions based on this key and value . For effective governance of infrastructure in cloud native approaches Semantic Versioning SemVer is sanest choice. While Micro/NanoService versioning typically is best suited to ComVer Cyvive 's integration with SemVer only tracks major minor patch the extensions format is stripped off for tracking purposes. If its necessary to modify governance information, then SemVer should be incremented to prevent cross-contamination of prior governed assets. Container images when using SemVer are not re-pulled from the image repository each time as they should and are assumed to be immutable. static labels i.e. latest can also be used with the understanding that configuration changes will be applied to all future deploymentTarget and container images will be re-pulled every time.","title":"NanoService"},{"location":"governance/configuration/#micronanoservice-yaml","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Info Scope: MicroService Specific File: cyvive.yaml Location: Git Repository / CI/CD Pushed","title":"Micro/NanoService YAML"},{"location":"governance/configuration/#understanding","text":"\u2026 core component of the Universal MicroServices Language . This file describes the specific MicroService Governance policy to be extracted and implemented on demand in a Cloud Agnostic Cluster. While Cyvive doesn't mandate a specific adoption approach, a truely minimal configuration file is achieved through following industry best practices for structure and oragnisation. Cyvive 's configuration language is architecturally and contexturally derived from partnership with 3 Universities and over 35 industry publications for providing a governance via policy meta-model that agnostically interfaces with the most complex orchestration technology while articulately able to be used in conversation. This file is a powerhouse behind agnostic infrastructure, and provides the most simple abstraction of deployment available today.","title":"Understanding"},{"location":"governance/configuration/#naming","text":"Cyvive aligns with Cloud Native and MicroServices approaches. However, this Universal MicroServices Language is flexible enough to be used with OSIMMv2 / TOGAF as such the following naming conventions apply: MicroServices : - Suite - Micro - Nano OSIMMv2 / TOGAF - Group - Suite - Service - Micro - Component - Nano CloudFunctions - Functions - Nano If your PaaS can efficiently start instances in 20ms that run for half a second, then call it serverless Adrian Cockcroft AWS VP - 2016 In the context of this quote, any well designed container with proper governance and management can be classified as a function . For this reason, Cyvive uses the terminology Nano instead of function to more appropriately cover the functions and nanoservices classifications.","title":"Naming"},{"location":"governance/configuration/#absolute-minimum-file-structure","text":"Note '\u21db' character is used throughout this documentation where items are mandatory with respect to the parent YAML key. If not specified, then item is optional. exampleSuite: \u21db exampleMicro: \u21db version: v1.8.x \u2026 this minimum structure is all that is necessary for Cyvive to commence governance and interface with the orchestration technology at a minimum level. If Cyvive was then used to govern this application / service in a deploymentTarget called 'preproduction' using the template 'perf' against Kubernetes as a orchestrator the following would happen: a Deployment would be created using the DockerHub hosted image: exampleSuite/exampleMicro:v1.8.x a Service would be created mapping port 80 to the Deployment a DNS entry would be created in the cluster as exampleMicro.exampleSuite.preproduction.svc.cluster.local any other applications governed by Cyvive 's and allowed to be deployed against this template would also be deployed following an automated dependency order. Note SemVer is rapidly becoming the version management approach of choice for development as it balances the needs of devoplers and continous container deployment well while maintaining business requirements for release management and change requests.","title":"Absolute Minimum File Structure"},{"location":"governance/configuration/#micronanoservice-inheritence-structure","text":"exampleSuite: \u21db exampleMicro: nano: identifier \u21db version: vTag \u2026 the typical structure used in a governance model would provide nano , micro , suite as units of categorization. Cyvive inherits this concept where typically suite would be a higher level Business Unit correctly decomposed containing a collection of MicroServices . The splitting point between micro and nano typically has a line of demarkation drawn between the need for an internal data model and direct algorithmic processing. The exact definition and demarkation of suites is left to the client, however by default when requesting a container from the container repository the format will be as such: - exampleSuite/exampleMicro:vTag or - exampleSuite/exampleMicro-exampleNano:vTag if nano key has been provided As such its possible to use Cyvive with any level of complexity in application relationships, while keeping isolation and deployment in a layered security approach.","title":"Micro/NanoService Inheritence Structure"},{"location":"governance/configuration/#suite-level-configuration-technology-descriptor","text":"exampleSuite exampleMicro: {} suite: {} \u2026 is available for all suites under governance. Where applicable identical specifications at the suite level override the template level. Its not necessary for suite information to be specified as a pre-requisite to adding a Micro/NanoService. It is possible for a Micro/NanoService to inherit configuration information from the suite level, thus allowing enhanced security over a traditional deployment model, where keys can be present in the application environment and unknown to developers with MicroService / NanoService source code access. Additional information on the suite Technology Descriptors is available","title":"Suite Level Configuration / Technology Descriptor"},{"location":"governance/configuration/#microservice-technology-descriptor","text":"exampleSuite exampleMicro: availability: {} circuitBreaker: {} commandLineInterface: {} component: string daemon: boolean endpoint: {} environment: {} label: {} layer: string repository: {} resource: {} security: {} stateful: {} version: {} \u2026 illustrates a high level overview of the logical configuration sections. Detailed information is located under each subheading below. Where values for keys are shown they are the default values.","title":"MicroService Technology Descriptor"},{"location":"governance/configuration/#availability","text":"exampleSuite: exampleMicro: availability: gracePeriod: boot: 1 stability: 0 termination: 5 minimum: 1 maximum: 2 probe: health: interval: 10 path: / port: 80 ready: interval: 5 path: / port: 80 timeout: 1 scalingEvent: {} gracePeriod : minimum time in seconds to wait for events to occur boot : Micro/NanoService operating system startup boot time, this should be the minimum time before a health check endpoint is available to process a request. stability : amount of time to wait for the health check endpoint to ensure consistent returns after boot time has been completed. This is typically used in legacy applications that need to stabilize their upstream and downstream communications when started or have large amounts of data to sync. termination : is the maximum amount of time to wait before hard terminating the container operating system. It does not guarantee the Micro/NanoService will have or take this long to terminate, its just the maximum amount of time to wait for the signal from the container operating system to ensure its okay to terminate. (Note: the termination signal is sent immediately to all container processes, this is the period before the kill signal is sent) minimum : guaranteed minimum number of replicas to always be deployed in the deploymentTarget maximum : when scaling ensure that this number is not exceeded probes : notify the underlying orchestrator of Micro/NanoService status. Where /health is actual health, and /ready is ability to recieve traffic interval : time in seconds for checking endpoint path : endpoint path relative to container port : internal port the probe endpoint is listening on timeout : this option is not nested under each probe as failures are being monitored for, its expected that timeout values should apply to all check related endpoints equally. scalingEvent : is a passthrough object of trigger events to integrate with orchestration support in triggering scaling up and down of the replicas. Note: With respect to deployment timeouts, Cyvive 's standard approach is to stall deployments as failed if the Micro/NanoService fails to enter ready state using one of the following timelines in order of priority rounded to the nearest second: probe.ready specified: (gracePeriod.boot + gracePeriod.stability + (probe.ready.interval * 2)) * 3.3 probe.health specified: (gracePeriod.boot + gracePeriod.stability + probe.health.interval) * 3.3 gracePeriod.stability : (gracePeriod.boot + gracePeriod.stability + 10) * 3.3 gracePeriod.boot : (gracePeriod.boot + 10) * 3.3 default settings : 33 seconds As seen above 10% buffer is applied to times to ensure container schedulling / restarting via the orchestrator doesn't introduce false-positives","title":"availability"},{"location":"governance/configuration/#circuitbreaker","text":"Info configuration structure still stabilizing","title":"circuitBreaker"},{"location":"governance/configuration/#commandlineinterface","text":"exampleSuite: exampleMicro: commandLineInterface: argument: [] command: \u2026 is an override path for container start commands. While most startups will embed the start command and respective arguments in the container image itself, efficient governance exposes all configuration, execution and dependency information. As such the organisation can choose to embed startup information in the container metadata or expose via governance layer. argument : standard cli arguments for execution. e.g. ['--list', '--debug'] command : root command to execute when starting the container. e.g. '/usr/local/bin/command' should this not be specified then the default command the container was built with will be executed.","title":"commandLineInterface"},{"location":"governance/configuration/#nano","text":"exampleSuite: exampleMicro: nano: \u2026 provides a namespace separation for nano Services. Typically used when the MicroService would need to be logicaly broken down further than is possible within the suite specification. Or when only algorithmic processing capabilities are necessary","title":"nano"},{"location":"governance/configuration/#daemon","text":"exampleSuite: exampleMicro: daemon: false \u2026 upgrades the Micro/NanoService to run as a Daemon in the deploymentTarget . This ensures that every physical node belonging to this suite will have this Daemon available on a low-latency local network hop.","title":"daemon"},{"location":"governance/configuration/#endpoint","text":"exampleSuite: exampleMicro: endpoint: domain: {} port: 80 provide: [ / ] scheme: https require: [] \u2026 are created for every Micro/NanoService by default and register DNS via the following schema: nanoName-microName.suiteName.deploymentTarget.domain port : open port for inbound interaction. provide : important for correct dependency management the provide endpoints are the registration points for Micro/NanoService searching and generation in the deployment graph. scheme : extensible against the scheme definitions in RFC standards, the key types are http and https where specifying https will cause auto-creation of SSL certificates at the cluster ingress point. Exploring the complex root keys: domain: xyz.com : [ DEVLIKE , HALIKE , PRODLIKE ] testing.co : [ DEVLIKE ] The domain object is structured as follows: - key : the domain name to expose against. This should be the Fully Qualified Domain Name ( FQDN ) as autogenerated DNS structure applies inside the cluster only. - value : array of operatingEnvironment 's valid for exposing against. Exposure follows the schema mentioned previously, however it can be overridden as necessary require: - redux.exampleSuite:443/api/v1/ending : [ incoming ] - exampleMicro.exampleSuite:80/v1/ : [ incoming , outgoing ] - 162.0.5.2:8080/ : [ outgoing ] The require object is quite important, and while optional, strongly recommended to always be supplied. It identifies all dependencies this Micro/NanoService has and helps contribute to the deployment order when creating a deploymentTarget . In the event a require is not registered with Cyvive it will be considered external to the cluster and assumed to already exist. A useful note is that different versions of the same Micro/NanoService can be consumed by other eachother. This is achieved via the version key where each governance technology descriptor registers against the Micro/NanoService version. The require object is structured as follows: - key : Uniform Resource Identifier (URI) RFC 3986 compliant. The scheme is unnecessary as any routing restrictions are scoped as above - value : traffic direction for filewall / security registration","title":"endpoint"},{"location":"governance/configuration/#environment","text":"exampleSuite: exampleMicro: environment: file: config: {} secret: {} variable: {} \u2026 all items are directly exposed to the Micro/NanoService. Exploring the complex root keys: files: config: alpha : mountPath: /alpha data: - name: configDetail value: string of information delta : inheritSuite: false Each item in config is a representation of a ConfigMap with individual items specified in the array object under data . Each item represents an individual file. mountPath is the directory location in the container that the ConfigMap should be mounted to. If inheritSuite is provided the configuration will be loaded from the suite settings enabling a more 'global' oriented view of configuration files: secrets: secretname : type: opaque mountPath: /secret-location data: - name: secretInfo value: (base64 string) anothersecret : inheritSuite: false Each item in secrets is a map with individual items under data representing files to be mounted into the mountPath location in the container. If inheritSuite is provided the secret will be loaded from the suite settings enabling a more 'global' oriented view of configuration variable: exposeName : exposeValue Direct mapping of the key to value provided as an environmental variable when executing the container start command. Additionally Cyvive exposes some helper variables to identify the current context of the Micro/NanoService: SELF_NAME : name of the Micro/NanoService. This will also be the hostname of the running container SELF_NAME_LOADBALANCER : to assist in discovery, this is the LoadBalancer endpoint for incluster communication to this container and its replicas. This is relative to the deploymentTarget and not the Fully Qualified Domain Name (FQDN) SELF_DEPLOYMENTTARGET : deploymentTarget that the Micro/NanoService has been deployed into SELF_IP : the internal cluster IP of the container The following self-explanatory variables are also available to the container when specified via Cyvive 's governance: SELF_MIN_MEMORY SELF_MIN_CPU SELF_MAX_MEMORY SELF_MAX_CPU","title":"environment"},{"location":"governance/configuration/#hardwired","text":"exampleSuite: exampleMicro: hardWired: clusterDNS: \u2026 is a catch-all for compatibility with non-governed processes. It is strongly recommended not to use these keys unless absolutely necessary as each key will disable some governance functionality and introduce independent manual management scenarios that wouldn't normally be necessary. clusterDNS : is a hard overwrite of the cluster internal load balancer endpoint for the Micro/NanoService. It disables the autogeneration capabilities and can help with initially migrating non Cloud Native items.","title":"hardWired"},{"location":"governance/configuration/#label","text":"exampleSuite: exampleMicro: label: # app: autocompleted ~ appName # component: autocompleted ~ component # release: autocompleted in PRODLIKE environments ~ canary or stable # tier: autocompleted ~ suiteName # version: autocompleted ~ version key {any others you require} Any labels not specified above can be used to help identify the applications services. As the aforeentioned labels are reserved by Cyvive for governance, any custom values provided will be ignored as they are used for asset tracking Although there is nothing stopping its use, the recommended approach is not to use hotfix as a label or blue / green for deploys as when running Micro/NanoServices en masse at scale, canary has been observed repeatedly as a more stable; reduced risk; and governable approach as everything passes through a 'canary' state anyway. (Under candidate based releases hotfixes are just releases that have been accelerated through the canary phase) Additionally, Cyvive uses Shadow Traffic Replication where return values are thrown away to prevent interference with production. This further provides isolation over the standard 'canary' approach validating the safety of the entire ecosystem to promote as a validated whole. There is no limit to how many labels can be specified","title":"label"},{"location":"governance/configuration/#layer","text":"exampleSuite: exampleMicro: layer: base \u2026 is a concept often used in Enterprise Architecture and earlier iterations of MicroServices. Cyvive underwent an extreemly careful active engagement process with its users prior to introducing this key. The layer concept is used as part of the dependency graph generation process. Prioritizing and guaranteeing deployments of each layer prior to commencing the next, failing fast when any layer fails to deploy. Layers in Order 1. data 2. communication 3. cache 4. backend 5. frontend While strictly not necessary to specify, if known the layer should be specified as it allows for accelerated parallel deployment in the desired deploymentTarget","title":"layer"},{"location":"governance/configuration/#repository","text":"exampleSuite exampleMicro: repository: image: domain: hub.docker name: exampleRedux officialImage: false owner: exampleRedux \u2026 image registry autogenerated name uses the format: repository/owner/name as such the default without image specified would be one of: - hub.docker/exampleSuite/exampleMicro or - hub.docker/exampleSuite/exampleMicro-exampleNano if nano key has been provided as seen earlier in repository This can be overriden to anything you need in any combination using the following values: domain : overrides suite or template domain settings name : overrides exampleMicro in the sample. This impacts deployed application name container image repository url generation. officialImage : is a structureal specification for DockerHub where official images have a different retrieval structure. Setting this as true would result in exampleMicro being the official image name or if provided name would still override to be the official image name. owner : override for owner in technology descriptor","title":"repository"},{"location":"governance/configuration/#resource","text":"exampleSuite: exampleMicro: resource: max: cpu: 500 memory: 1Gi min: cpu: 300 memory: 1Gi qos: \u2026 allocation is an important part of all container orchestration schedullers, and these values should be provided prior to deploying Micro/NanoService to production deploymentTarget although, if not specified Cyvive will operate without issue. max absolute maximum requirements that we are prepared to allocate. min minimum required in order to guarantee application boot and ready for traffic interaction. qos is mandatory should min or max be specified If neither min or max are specified then template defaults (if specified) will be used. The ability to provide template resource defaults is to ensure safe co-habitation of Services / Applications / Components when / if they go rogue. cpu is units of CPU core specified in 'm' thus for a single CPU core 1000 should be used. The 'm' is omitted and should not be specified. memory should always have the multiplier specified as part of the value i.e. 'Gi' any suitable value can be specified from the following: Ki Mi Gi Ti Pi Ei qos follows the approach: guaranteed : highest possible level, everything not this level will suffer 'pause' events to ensure these pods continue to operate. burstable : default min values are allocated to the pod as minimum required to run. No upper limits are placed on resources. effort : can be used when the application is lowest priority of them all. min , max and namespace default values are totally ignored. (Currently un-implemented due to lack of user demand)","title":"resource"},{"location":"governance/configuration/#security","text":"Info configuration structure still stabilizing exampleSuite: exampleMicro: security: account: name: alternativeOne reference: admin account : should an account be required that isn't the suite security account or 'default' i.e. another suite's account. It can be overriden here. Specifying will create the account if it doesn't exist","title":"security"},{"location":"governance/configuration/#stateful","text":"Info configuration structure still stabilizing exampleSuite: exampleMicro stateful: cloudNative: false databaseName: individualServices: false replica: 3 sharedStorage: false volume: avolume : mountPath: /avolume size: 10Gi storageClass: cloudNative : Enables the ability to deploy stateful applications in parallel and will automatically compact number of replicas down in envionments that aren't 'HALIKE' or 'PRODLIKE' to save resources. databaseName : standard application naming will be applied if this field is omitted. Its frequently used in custom templates for configuring some of the expected internals individualServices : some applications can operate under a common service endpoint, others such as MongoDB require fixed service endpoints for each database replica : number of PODS that should be deployed, if the backend supports it anti-affinity rules will already be in place per Availablility Zone and Host. sharedStorage : determines if the PODS should have mount the same storage or have unique storage per pod ( warhing multi-mount storage is unsupported by most storage drivers) storageClass : the type of storage strategy that should be applied In providing a consistent minimal configuration the stateful configuration integrates with endpoint and it should be used for accessing accordingly Amount of time that should be given after sending kill signal to the container OS before terminating and removing the container.","title":"stateful"},{"location":"governance/configuration/#version","text":"exampleSuite: exampleMicro: version: latest \u2026 standards and application is a constantly debated aproach with different internal standards used within organizations. Internally Cyvive maintains governance versions based on this key and value . For effective governance of infrastructure in cloud native approaches Semantic Versioning SemVer is sanest choice. While Micro/NanoService versioning typically is best suited to ComVer Cyvive 's integration with SemVer only tracks major minor patch the extensions format is stripped off for tracking purposes. If its necessary to modify governance information, then SemVer should be incremented to prevent cross-contamination of prior governed assets. Container images when using SemVer are not re-pulled from the image repository each time as they should and are assumed to be immutable. static labels i.e. latest can also be used with the understanding that configuration changes will be applied to all future deploymentTarget and container images will be re-pulled every time.","title":"version"},{"location":"governance/configuration/suites/","text":"Suite YAML Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Info Scope: Suite for Micro/NanoService Inheritence File: *.suite.yaml Location: Governance Repository / CI/CD Pushed Understanding \u2026 core component of the Universal MicroServices Language . This file describes the specific suite level governance policy to be extracted and implemented on demand in the cluster orchestration infrastructure against Micro/NanoService registered against this suite. Cyvive 's configuration language is architecturally and contexturally derived from partnership with 3 Universities and over 35 industry publications for providing a governance via policy meta-model that agnostically interfaces with the most complex orchestration technology while articulately able to be used in conversation. This file is a powerhouse behind agnostic infrastructure, and provides the most simple abstraction of deployment available today. Group Level Configuration / Technology Descriptor exampleGroup: suite: environment: {} repository: image: auth: {} domain: hub.docker.io owner: exampleRedux security: {} \u2026 suite is a reserved keyword. It directly specifies that all keys present are applied to all Micro/NanoServices also registered against the suite. environment \u2026 structural copy of Micro/NanoService Environment repository exampleGroup: suite: repository: image: auth: {} domain: hub.docker.io owner: exampleRedux \u2026 defaults for Micro/NanoServices related to this suite . Typically the suite would map directly to a business unit or complex service. Based on this, the suite 's may be logically stored in different image repositories. There are some differences from Micro/NanoService Repository as can be seen below image: auth: exampleGroup : ZmF0aG9tYWJsZQo= domain: gcr.io owner: internal auth : is a series of base64 encoded objects containing the Docker login information. domain : container repository domain information, this will become the default for all items registered against this suite owner : change the default owner from the suite name (e.g. exampleGroup) for all items registered against this suite security \u2026 structural copy of Micro/NanoService Security","title":"Suite of Services"},{"location":"governance/configuration/suites/#suite-yaml","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Info Scope: Suite for Micro/NanoService Inheritence File: *.suite.yaml Location: Governance Repository / CI/CD Pushed","title":"Suite YAML"},{"location":"governance/configuration/suites/#understanding","text":"\u2026 core component of the Universal MicroServices Language . This file describes the specific suite level governance policy to be extracted and implemented on demand in the cluster orchestration infrastructure against Micro/NanoService registered against this suite. Cyvive 's configuration language is architecturally and contexturally derived from partnership with 3 Universities and over 35 industry publications for providing a governance via policy meta-model that agnostically interfaces with the most complex orchestration technology while articulately able to be used in conversation. This file is a powerhouse behind agnostic infrastructure, and provides the most simple abstraction of deployment available today.","title":"Understanding"},{"location":"governance/configuration/suites/#group-level-configuration-technology-descriptor","text":"exampleGroup: suite: environment: {} repository: image: auth: {} domain: hub.docker.io owner: exampleRedux security: {} \u2026 suite is a reserved keyword. It directly specifies that all keys present are applied to all Micro/NanoServices also registered against the suite.","title":"Group Level Configuration / Technology Descriptor"},{"location":"governance/configuration/suites/#environment","text":"\u2026 structural copy of Micro/NanoService Environment","title":"environment"},{"location":"governance/configuration/suites/#repository","text":"exampleGroup: suite: repository: image: auth: {} domain: hub.docker.io owner: exampleRedux \u2026 defaults for Micro/NanoServices related to this suite . Typically the suite would map directly to a business unit or complex service. Based on this, the suite 's may be logically stored in different image repositories. There are some differences from Micro/NanoService Repository as can be seen below image: auth: exampleGroup : ZmF0aG9tYWJsZQo= domain: gcr.io owner: internal auth : is a series of base64 encoded objects containing the Docker login information. domain : container repository domain information, this will become the default for all items registered against this suite owner : change the default owner from the suite name (e.g. exampleGroup) for all items registered against this suite","title":"repository"},{"location":"governance/configuration/suites/#security","text":"\u2026 structural copy of Micro/NanoService Security","title":"security"},{"location":"governance/configuration/templates/","text":"Templates YAML Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Info Scope: deploymentTarget File: *.template.yaml Understanding \u2026 core component of the Universal MicroServices Language . This file describes the template 's available for deploymentTarget to be created from. Its the highest level of inheritance for governance and configuration when deploying a collection of Micro/NanoServices into a deploymentTarget . Specified items are inherited as low priority defaults unless overriden. Cyvive 's configuration language is architecturally and contexturally derived from partnership with 3 Universities and over 35 industry publications for providing a governance via policy meta-model that agnostically interfaces with the most complex orchestration technology while articulately able to be used in conversation. This file is a powerhouse behind agnostic infrastructure, and provides the most simple abstraction of deployment available today. Template Technology Descriptors \u2026 are logically grouped into four meta-categories, and while the individual template can have any name assigned to it, the template must belong to a meta-category. Where each meta-catagory is based on the following operatingEnvironment logical progression: development \u21db high availability development \u21db performance \u21db production Default Template Names dev (type: development ) - single container availability - minimum resource allocation - probes: - ready ha (type: high availability development ) - dual container availability - minimum resource allocation - probes: - ready perf (type: performance ) - dual container availability - maximum resource allocation - probes: - ready - health prod (type: production ) - high availability - horizonal autoscaling - maximum resource allocation - probes: - ready - health template type selection is controlled via the operatingEnvironment field. The following states select the operatingEnvironment : - [] @ dev (default) - ['DEVLIKE'] @ dev (alterantive for direct specification) - ['HALIKE'] @ ha - ['PRODLIKE'] @ prod - ['HALIKE', 'PRODLIKE'] @ perf This approach enables any number of copies or versions of deploymentTarget to be deployed or updated with identical or slightly varied configuration. Additionally as the governance process is version aware, multiple versions of the Micro/NanoService can co-exist in the same deploymentTarget Cyvive.io provides this default set of Template Technology Descriptors not to enforce direction on organisations but to assist with rapid adoption and integration with existing processes. The default Templates cover all operatingEnvironment types that an organization would utilize in developing and promoting an Micro/NanoService through its Continuous Delivery / Deployment lifecycle. While isolating and adding the infrastructure complexities step by step to assist with narrowing debugging focus. When creating a deploymentTarget Cyvive.io will deploy in parallel constrained by priority order all Micro/NanoServices relying on the container orchestration technology to confirm that each Micro/NanoService has started correctly. Should a service fail to start the failure will be reported back, otherwise a sucess response will be recieved. Root Structure dev: ha: perf: prod: mandatory: (others) As mentioned previously any custom name can be used for a template except mandatory as its a reserved operatingEnvironment : All information populated in this key will be deployed into all deploymentTarget 's Should mandatory be used, it follows the same structure as Cyvive.io 's Micro/NanoService with the exception of groups as the mandatory key replaces the group key. As such the dedicated group configuration is also unavailable for mandatory Template Technology Descriptor Note '\u21db' character is used throughout this documentation where items are mandatory with respect to the parent YAML key. If not specified, then item is optional. example: environment: {} \u21db operatingEnvironment: [] resource: {} environment \u2026 structural copy of Micro/NanoService Environment operatingEnvironment dev: \u21db operatingEnvironment: \u21db [] template type selection is controlled via the operatingEnvironment field. The following states select the operatingEnvironment : - [] @ dev (default) - ['DEVLIKE'] @ dev (alterantive for direct specification) - ['HALIKE'] @ ha - ['PRODLIKE'] @ prod - ['HALIKE', 'PRODLIKE'] @ perf resource \u2026 structural copy of Micro/NanoService Resource","title":"Templates"},{"location":"governance/configuration/templates/#templates-yaml","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Info Scope: deploymentTarget File: *.template.yaml","title":"Templates YAML"},{"location":"governance/configuration/templates/#understanding","text":"\u2026 core component of the Universal MicroServices Language . This file describes the template 's available for deploymentTarget to be created from. Its the highest level of inheritance for governance and configuration when deploying a collection of Micro/NanoServices into a deploymentTarget . Specified items are inherited as low priority defaults unless overriden. Cyvive 's configuration language is architecturally and contexturally derived from partnership with 3 Universities and over 35 industry publications for providing a governance via policy meta-model that agnostically interfaces with the most complex orchestration technology while articulately able to be used in conversation. This file is a powerhouse behind agnostic infrastructure, and provides the most simple abstraction of deployment available today.","title":"Understanding"},{"location":"governance/configuration/templates/#template-technology-descriptors","text":"\u2026 are logically grouped into four meta-categories, and while the individual template can have any name assigned to it, the template must belong to a meta-category. Where each meta-catagory is based on the following operatingEnvironment logical progression: development \u21db high availability development \u21db performance \u21db production","title":"Template Technology Descriptors"},{"location":"governance/configuration/templates/#default-template-names","text":"dev (type: development ) - single container availability - minimum resource allocation - probes: - ready ha (type: high availability development ) - dual container availability - minimum resource allocation - probes: - ready perf (type: performance ) - dual container availability - maximum resource allocation - probes: - ready - health prod (type: production ) - high availability - horizonal autoscaling - maximum resource allocation - probes: - ready - health template type selection is controlled via the operatingEnvironment field. The following states select the operatingEnvironment : - [] @ dev (default) - ['DEVLIKE'] @ dev (alterantive for direct specification) - ['HALIKE'] @ ha - ['PRODLIKE'] @ prod - ['HALIKE', 'PRODLIKE'] @ perf This approach enables any number of copies or versions of deploymentTarget to be deployed or updated with identical or slightly varied configuration. Additionally as the governance process is version aware, multiple versions of the Micro/NanoService can co-exist in the same deploymentTarget Cyvive.io provides this default set of Template Technology Descriptors not to enforce direction on organisations but to assist with rapid adoption and integration with existing processes. The default Templates cover all operatingEnvironment types that an organization would utilize in developing and promoting an Micro/NanoService through its Continuous Delivery / Deployment lifecycle. While isolating and adding the infrastructure complexities step by step to assist with narrowing debugging focus. When creating a deploymentTarget Cyvive.io will deploy in parallel constrained by priority order all Micro/NanoServices relying on the container orchestration technology to confirm that each Micro/NanoService has started correctly. Should a service fail to start the failure will be reported back, otherwise a sucess response will be recieved.","title":"Default Template Names"},{"location":"governance/configuration/templates/#root-structure","text":"dev: ha: perf: prod: mandatory: (others) As mentioned previously any custom name can be used for a template except mandatory as its a reserved operatingEnvironment : All information populated in this key will be deployed into all deploymentTarget 's Should mandatory be used, it follows the same structure as Cyvive.io 's Micro/NanoService with the exception of groups as the mandatory key replaces the group key. As such the dedicated group configuration is also unavailable for mandatory","title":"Root Structure"},{"location":"governance/configuration/templates/#template-technology-descriptor","text":"Note '\u21db' character is used throughout this documentation where items are mandatory with respect to the parent YAML key. If not specified, then item is optional. example: environment: {} \u21db operatingEnvironment: [] resource: {}","title":"Template Technology Descriptor"},{"location":"governance/configuration/templates/#environment","text":"\u2026 structural copy of Micro/NanoService Environment","title":"environment"},{"location":"governance/configuration/templates/#operatingenvironment","text":"dev: \u21db operatingEnvironment: \u21db [] template type selection is controlled via the operatingEnvironment field. The following states select the operatingEnvironment : - [] @ dev (default) - ['DEVLIKE'] @ dev (alterantive for direct specification) - ['HALIKE'] @ ha - ['PRODLIKE'] @ prod - ['HALIKE', 'PRODLIKE'] @ perf","title":"operatingEnvironment"},{"location":"governance/configuration/templates/#resource","text":"\u2026 structural copy of Micro/NanoService Resource","title":"resource"},{"location":"governance/endpoints/","text":"Overview Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Summary Understanding how Cyvive.io 's exposed (behind a security layer) API's operate and expected results when interacting with them. Resoning Security and the ability to easily integrate with the existing enterprise technology stack is paramount to success for long-term adoption of any product. As Cyvive.io is dircetly interacting with the underlying container orchestration plaform, its essential that Cyvive.io 's security levels are as strong as what would be used in the cluster or higher. All REST API's are protected by MultiFactorAuthentication This section provides detailed information on each of the available REST API's, their requirements, returned values and expected results of what will occur in the cluster.","title":"Overview"},{"location":"governance/endpoints/#overview","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Summary Understanding how Cyvive.io 's exposed (behind a security layer) API's operate and expected results when interacting with them.","title":"Overview"},{"location":"governance/endpoints/#resoning","text":"Security and the ability to easily integrate with the existing enterprise technology stack is paramount to success for long-term adoption of any product. As Cyvive.io is dircetly interacting with the underlying container orchestration plaform, its essential that Cyvive.io 's security levels are as strong as what would be used in the cluster or higher. All REST API's are protected by MultiFactorAuthentication This section provides detailed information on each of the available REST API's, their requirements, returned values and expected results of what will occur in the cluster.","title":"Resoning"},{"location":"governance/endpoints/flow/","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. flow/ POST: (GitHub New Branch Event) 201 - :branch === namespace to create GET: all namespaces tracked by Cyvive.io DELETE: (GitHub Branch Delete Events)","title":"Flow"},{"location":"governance/endpoints/ingest/","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. ingest POST: (GitHub Push Events - matches to tracked apps / dumps if not tracked)","title":"Ingest"},{"location":"governance/endpoints/keys/","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. security/ //Key management for group decryption POST GET PATCH DELETE","title":"Keys"},{"location":"governance/endpoints/namespace/","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. /namespace (manual interactions) POST: create any from template + register with flow GET: /all /manual /flow (managed vs automated) DELETE: kubectl --delete namespace wrapper + deregister with flow","title":"Namespace"},{"location":"governance/endpoints/release/","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate.","title":"Release"},{"location":"governance/endpoints/tracker/","text":"Tracker Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Summary Auto-management of application infrastructure requirements and container change tracking REST Routes Note structure: {{TYPE}} {{ROUTE}} {{JSON BODY}} Tracker Names follow the format: group.name DELETE /trackers/{{group}}.{{name}} GET /trackers/ {} ~ returns all active trackers. For security reasons, this does not container the OAUTH tokens used for GitHub access GET /trackers/{{group}}.{{name}} {} ~ returns a specific tracker by name POST /trackers/ PUT /trackers/{{group}}.{{name}} { id: 'string', token: 'string', repo: 'string', sourcePath: 'string', tag: 'string' ~ optional branch: 'string' ~ optional commit: 'string' ~ optional } Enabling Any of the deployment patterns can be used to enable tracking functionality. The general approach is to start with a vanilla cluster, and enable tracking for each application to be managed by Cyvive.io . By sending a POST request. When tracking is enabled Cyvive.io will injest the cyvive.yaml file in the GitHub repository and configure accordingly. Approach Once the application has been added to tracker one of several scenarios can occur: cyvive.yaml in application's GitHub repo is modified. Application container is updated New Version of Application container is created In scenario 1, Cyvive.io will que the configuration changes until scenario 2 or 3 occur. This guarantees that updated infrastructure requirements are not applied to non-prepped containers. In scenario 2 or 3 Cyvive.io will add to dev release que. Preferred Versioning Container labels, can be either fixed or follow SemVer standards. Tracking module polls both GitHub Container Image Repository for changes / updates to images via API hashes (container images are not downloaded)","title":"Tracker"},{"location":"governance/endpoints/tracker/#tracker","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Summary Auto-management of application infrastructure requirements and container change tracking","title":"Tracker"},{"location":"governance/endpoints/tracker/#rest-routes","text":"Note structure: {{TYPE}} {{ROUTE}} {{JSON BODY}} Tracker Names follow the format: group.name DELETE /trackers/{{group}}.{{name}} GET /trackers/ {} ~ returns all active trackers. For security reasons, this does not container the OAUTH tokens used for GitHub access GET /trackers/{{group}}.{{name}} {} ~ returns a specific tracker by name POST /trackers/ PUT /trackers/{{group}}.{{name}} { id: 'string', token: 'string', repo: 'string', sourcePath: 'string', tag: 'string' ~ optional branch: 'string' ~ optional commit: 'string' ~ optional }","title":"REST Routes"},{"location":"governance/endpoints/tracker/#enabling","text":"Any of the deployment patterns can be used to enable tracking functionality. The general approach is to start with a vanilla cluster, and enable tracking for each application to be managed by Cyvive.io . By sending a POST request. When tracking is enabled Cyvive.io will injest the cyvive.yaml file in the GitHub repository and configure accordingly.","title":"Enabling"},{"location":"governance/endpoints/tracker/#approach","text":"Once the application has been added to tracker one of several scenarios can occur: cyvive.yaml in application's GitHub repo is modified. Application container is updated New Version of Application container is created In scenario 1, Cyvive.io will que the configuration changes until scenario 2 or 3 occur. This guarantees that updated infrastructure requirements are not applied to non-prepped containers. In scenario 2 or 3 Cyvive.io will add to dev release que.","title":"Approach"},{"location":"governance/endpoints/tracker/#preferred-versioning","text":"Container labels, can be either fixed or follow SemVer standards. Tracking module polls both GitHub Container Image Repository for changes / updates to images via API hashes (container images are not downloaded)","title":"Preferred Versioning"},{"location":"governance/extending/plugins/","text":"Extending with custom Plugins Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Summary integrating with the core Cyvive.io functionalities for custom gain. Architecturally Cyvive.io provides a series of custom events and actions that can be called as part of the core functionality. These are supported endpoints and are stable datastrutures that can be hooked into for any plugin development. These endpoints can also handle middleware, should the need arise. Events core events emitted regularly are as follows: generated:app generated:group generated:namespace updated:github updated:container configSync:check configSync:update isReady regenerate:app regenerate:group regenerate:ns refresh:generated refresh:db initDB","title":"Extending with custom Plugins"},{"location":"governance/extending/plugins/#extending-with-custom-plugins","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Summary integrating with the core Cyvive.io functionalities for custom gain. Architecturally Cyvive.io provides a series of custom events and actions that can be called as part of the core functionality. These are supported endpoints and are stable datastrutures that can be hooked into for any plugin development. These endpoints can also handle middleware, should the need arise.","title":"Extending with custom Plugins"},{"location":"governance/extending/plugins/#events","text":"core events emitted regularly are as follows: generated:app generated:group generated:namespace updated:github updated:container configSync:check configSync:update isReady regenerate:app regenerate:group regenerate:ns refresh:generated refresh:db initDB","title":"Events"},{"location":"governance/usage/developer/","text":"QuickStart: Usage for Developers Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Governance Overview Cyvive.io is Cloud Native Layer 4 - 7 OSIMM Compliant and as such implements a Governance via Policy approach through YAML configuration files created per Micro/NanoService. The language used in configuration description is not arbritary, and is architecturally and contexturally derived from partnership with 3 Universities and over 35 industry publications with containerization viewpoint spanning from MicroServices Architecture through to Enteprise Architecture principles. The configuration approach is powerful enough to handle governance of any type of application in the modern technology stack including 'cloud functions' while being flexible enough to be used in ordinary conversation between teams, departments and vendors. A detailed explanation of the configuration options is available Enabling Governance of your Micro/NanoService \u2026 is accomplished via a POST call to Cyvive.io . If running via the provided 'httpie' container http POST cyvive:3000/data technologyDescriptor:= { exampleGroup : { exampleApp : { version : v1.8.x }}} YAML as a string can also be provided if required under the technologyDescriptorYAML parameter Governance assets are automatically versioned based on the version parameter Deploying a Governed Micro/NanoService \u2026 is also done via POST call. If running via the provided 'httpie' container http POST cyvive:3000/namespace deploymentTarget=development require:= [ exampleApp.exampleGroup/ ] template=dev Briefly expanding the parameters: deploymentTarget is the namespace / environment that Cyvive.io should create or update require albiet an optional field will be used frequently by all developers. It provides the root of the governed dependency tree(s) to be deployed. As Cyvive.io is Layer 7 compliant each require is a Uniform Resource Identifier (URI) template is a higher level Governance Technology Descriptor. At its core separated into 4 logicical types (development ( dev ) = high availability ( ha ) = performance ( perf ) = production ( production )) with the default names provided in bold. Any number of template (s) can be created with custom names for each as long as they map to one of the core types for enabling / disabling elevated functionality. Additional information is available Removing a deploymentTarget \u2026 accomplished via standard DELETE call. If running via the provided 'httpie' container http DELETE cyvive:3000/namespace/development Purging a Micro/NanoService from Governance \u2026 accomplished via standard DELETE call. If running via the provided 'httpie' container http DELETE cyvive:3000/data/exampleGroup.exampleApp This will not actively purge any deployed assets in targets, just this asset from Governance and by defacto future deployments. Additional Reading / Information QuickStart: Govenor Cyvive.io Configuration Cyvive.io Endpoints Single Application / Service Example Multiple Application / Service Example {migrating} Dependecy Application / Service Example {migrating}","title":"Developer"},{"location":"governance/usage/developer/#quickstart-usage-for-developers","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate.","title":"QuickStart: Usage for Developers"},{"location":"governance/usage/developer/#governance-overview","text":"Cyvive.io is Cloud Native Layer 4 - 7 OSIMM Compliant and as such implements a Governance via Policy approach through YAML configuration files created per Micro/NanoService. The language used in configuration description is not arbritary, and is architecturally and contexturally derived from partnership with 3 Universities and over 35 industry publications with containerization viewpoint spanning from MicroServices Architecture through to Enteprise Architecture principles. The configuration approach is powerful enough to handle governance of any type of application in the modern technology stack including 'cloud functions' while being flexible enough to be used in ordinary conversation between teams, departments and vendors. A detailed explanation of the configuration options is available","title":"Governance Overview"},{"location":"governance/usage/developer/#enabling-governance-of-your-micronanoservice","text":"\u2026 is accomplished via a POST call to Cyvive.io . If running via the provided 'httpie' container http POST cyvive:3000/data technologyDescriptor:= { exampleGroup : { exampleApp : { version : v1.8.x }}} YAML as a string can also be provided if required under the technologyDescriptorYAML parameter Governance assets are automatically versioned based on the version parameter","title":"Enabling Governance of your Micro/NanoService"},{"location":"governance/usage/developer/#deploying-a-governed-micronanoservice","text":"\u2026 is also done via POST call. If running via the provided 'httpie' container http POST cyvive:3000/namespace deploymentTarget=development require:= [ exampleApp.exampleGroup/ ] template=dev Briefly expanding the parameters: deploymentTarget is the namespace / environment that Cyvive.io should create or update require albiet an optional field will be used frequently by all developers. It provides the root of the governed dependency tree(s) to be deployed. As Cyvive.io is Layer 7 compliant each require is a Uniform Resource Identifier (URI) template is a higher level Governance Technology Descriptor. At its core separated into 4 logicical types (development ( dev ) = high availability ( ha ) = performance ( perf ) = production ( production )) with the default names provided in bold. Any number of template (s) can be created with custom names for each as long as they map to one of the core types for enabling / disabling elevated functionality. Additional information is available","title":"Deploying a Governed Micro/NanoService"},{"location":"governance/usage/developer/#removing-a-deploymenttarget","text":"\u2026 accomplished via standard DELETE call. If running via the provided 'httpie' container http DELETE cyvive:3000/namespace/development","title":"Removing a deploymentTarget"},{"location":"governance/usage/developer/#purging-a-micronanoservice-from-governance","text":"\u2026 accomplished via standard DELETE call. If running via the provided 'httpie' container http DELETE cyvive:3000/data/exampleGroup.exampleApp This will not actively purge any deployed assets in targets, just this asset from Governance and by defacto future deployments.","title":"Purging a Micro/NanoService from Governance"},{"location":"governance/usage/developer/#additional-reading-information","text":"QuickStart: Govenor Cyvive.io Configuration Cyvive.io Endpoints Single Application / Service Example Multiple Application / Service Example {migrating} Dependecy Application / Service Example {migrating}","title":"Additional Reading / Information"},{"location":"governance/usage/govenor/","text":"QuickStart: Usage for Govenors Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate. Governance Overview Cyvive.io is Cloud Native Layer 4 - 7 OSIMM Compliant and as such implements a Governance via Policy approach through YAML configuration files created per Micro/NanoService. The language used in configuration description is not arbritary, and is architecturally and contexturally derived from partnership with 3 Universities and over 35 industry publications with containerization viewpoint spanning from MicroServices Architecture through to Enteprise Architecture principles. The configuration approach is powerful enough to handle governance of any type of application in the modern technology stack including 'cloud functions' while being flexible enough to be used in ordinary conversation between teams, departments and vendors. A detailed explanation of the configuration options is available Micro/NanoService Overview \u2026 is best described through the Usage for Developers quickstart. Governance Inheritence Tree \u2026 is a Don't Repeat Yourself ( DRY ) approach. As such configuration follows an inheritance path overlaying prior configuration settings where necessary. Overrides: template \u21db suite \u21db micro/nanoservice The use of this inheritance model also allows a segregation of security concerns where naturally authorized individuals interact with the correct Governance layers for enterprise and whole company management of Services. Template Technology Descriptors \u2026 are logically grouped into four meta-categories, and while the individual template can have any name assigned to it, the template must belong to a meta-category. Where each meta-catagory is based on the following operatingEnvironment logical progression: development \u21db high availability development \u21db performance \u21db production Default Template Names dev (type: development ) - single container availability - minimum resource allocation - probes: - ready ha (type: high availability development ) - dual container availability - minimum resource allocation - probes: - ready perf (type: performance ) - dual container availability - maximum resource allocation - probes: - ready - health prod (type: production ) - high availability - horizonal autoscaling - maximum resource allocation - probes: - ready - health template type selection is controlled via the type field. The following states select the operatingEnvironment : - [] @ dev (default) - ['DEVLIKE'] @ dev (alterantive for direct specification) - ['HALIKE'] @ ha - ['PRODLIKE'] @ prod - ['HALIKE', 'PRODLIKE'] @ perf Additional information on the template Technology Descriptors is available Adding a Template Technology Descriptor \u2026 accomplished via a standard POST call. If running via the provided 'httpie' container http POST cyvive:3000/template technologyDescriptor:= { customName : {type: [ HADEV ]}} Removing a Template Technology Descriptor \u2026 accomplished via standard DELETE call. If running via the provided 'httpie' container http DELETE cyvive:3000/template/customName This will not remove any existing deploymentTarget 's that utilizing this template it will just remove the template from future deploymentTarget . Group Technology Descriptor \u2026 is available for all groups under governance. Where applicable identical specifications at the group level override the template level. Its not necessary for group information to be specified as a pre-requisite to adding a Micro/NanoService to a non-existent group. It is possible Micro/NanoService to inherit configuration information from the group level, thus allowing enhanced security over a traditional deployment model, where keys can be present in the application environment and unknown to developers with Micro/NanoService source code access. Additional information on the group Technology Descriptors is available Additional Reading / Information QuickStart: Developer Cyvive.io Configuration Cyvive.io Endpoints Single Application / Service Example Multiple Application / Service Example {migrating} Dependecy Application / Service Example {migrating}","title":"Govenor"},{"location":"governance/usage/govenor/#quickstart-usage-for-govenors","text":"Warning This functionality was originally offered by the parent company as a separate product Fathomable . It is undergoing consolidation into Cyvive 's core and is restricted to beta customers at this time. Please contact your account manager via live-chat should you wish to participate.","title":"QuickStart: Usage for Govenors"},{"location":"governance/usage/govenor/#governance-overview","text":"Cyvive.io is Cloud Native Layer 4 - 7 OSIMM Compliant and as such implements a Governance via Policy approach through YAML configuration files created per Micro/NanoService. The language used in configuration description is not arbritary, and is architecturally and contexturally derived from partnership with 3 Universities and over 35 industry publications with containerization viewpoint spanning from MicroServices Architecture through to Enteprise Architecture principles. The configuration approach is powerful enough to handle governance of any type of application in the modern technology stack including 'cloud functions' while being flexible enough to be used in ordinary conversation between teams, departments and vendors. A detailed explanation of the configuration options is available","title":"Governance Overview"},{"location":"governance/usage/govenor/#micronanoservice-overview","text":"\u2026 is best described through the Usage for Developers quickstart.","title":"Micro/NanoService Overview"},{"location":"governance/usage/govenor/#governance-inheritence-tree","text":"\u2026 is a Don't Repeat Yourself ( DRY ) approach. As such configuration follows an inheritance path overlaying prior configuration settings where necessary. Overrides: template \u21db suite \u21db micro/nanoservice The use of this inheritance model also allows a segregation of security concerns where naturally authorized individuals interact with the correct Governance layers for enterprise and whole company management of Services.","title":"Governance Inheritence Tree"},{"location":"governance/usage/govenor/#template-technology-descriptors","text":"\u2026 are logically grouped into four meta-categories, and while the individual template can have any name assigned to it, the template must belong to a meta-category. Where each meta-catagory is based on the following operatingEnvironment logical progression: development \u21db high availability development \u21db performance \u21db production","title":"Template Technology Descriptors"},{"location":"governance/usage/govenor/#default-template-names","text":"dev (type: development ) - single container availability - minimum resource allocation - probes: - ready ha (type: high availability development ) - dual container availability - minimum resource allocation - probes: - ready perf (type: performance ) - dual container availability - maximum resource allocation - probes: - ready - health prod (type: production ) - high availability - horizonal autoscaling - maximum resource allocation - probes: - ready - health template type selection is controlled via the type field. The following states select the operatingEnvironment : - [] @ dev (default) - ['DEVLIKE'] @ dev (alterantive for direct specification) - ['HALIKE'] @ ha - ['PRODLIKE'] @ prod - ['HALIKE', 'PRODLIKE'] @ perf Additional information on the template Technology Descriptors is available","title":"Default Template Names"},{"location":"governance/usage/govenor/#adding-a-template-technology-descriptor","text":"\u2026 accomplished via a standard POST call. If running via the provided 'httpie' container http POST cyvive:3000/template technologyDescriptor:= { customName : {type: [ HADEV ]}}","title":"Adding a Template Technology Descriptor"},{"location":"governance/usage/govenor/#removing-a-template-technology-descriptor","text":"\u2026 accomplished via standard DELETE call. If running via the provided 'httpie' container http DELETE cyvive:3000/template/customName This will not remove any existing deploymentTarget 's that utilizing this template it will just remove the template from future deploymentTarget .","title":"Removing a Template Technology Descriptor"},{"location":"governance/usage/govenor/#group-technology-descriptor","text":"\u2026 is available for all groups under governance. Where applicable identical specifications at the group level override the template level. Its not necessary for group information to be specified as a pre-requisite to adding a Micro/NanoService to a non-existent group. It is possible Micro/NanoService to inherit configuration information from the group level, thus allowing enhanced security over a traditional deployment model, where keys can be present in the application environment and unknown to developers with Micro/NanoService source code access. Additional information on the group Technology Descriptors is available","title":"Group Technology Descriptor"},{"location":"governance/usage/govenor/#additional-reading-information","text":"QuickStart: Developer Cyvive.io Configuration Cyvive.io Endpoints Single Application / Service Example Multiple Application / Service Example {migrating} Dependecy Application / Service Example {migrating}","title":"Additional Reading / Information"},{"location":"platform/","text":"In Relation to Cloud Native Cloud Native Computing Foundaton (CNCF) graduated two significant projects that have disrupted the Information Technology industry at a scarcely precedented scale. Kubernetes and ContainerD . It is no co-incidence that Cyvive is an enabler for both technologies. Kubernetes has been utilized and supported by Cyvive since September 2016 (Kubernetes 1.6.x) ContainerD literally provides the operating system Cyvive has utilized since shortly after Google Kubernetes Engine was released, making us one of the early adopters of the technology. Enterprise Acceleration Speed, Scale, Margin ; is the core mantra of most (if not all) Enterprise today. In fact, such is the drive for these three key factors, that the restraint on progress is no longer human related, but reaction related. A clear example in point is, churn rate for unorchestrated containers is roughly once every 6 days , wherease orchestrated containers are 2x a day , or 12 times faster. If your infrastructure is capable of operating at scale and speed, development will rise to meet the restraints. Security With the advent of DevSecOps there is sane reason why Security is not defacto included with Speed, Scale, Margin . For Cyvive , security is so critical that every part of its operation puts security first. Notable functionality being: \u2020Immutability: Every deployed node is Immutable. From the Control plane, through to storage nodes. If a breach did occur, the node can be terminated without adverse affects to the workload. Container Certification: Containers are by default blacklisted from deployment into Kubernetes, unless they pass required security rules such as No CVE's present that a patch is available for \u2020Deploys into existing Enterprise Setup Cloud Network \u2020Cloud Provisioning continually reviewed and developed in conjunction with Cloud Certified Engineers \u2020TTY and SSH disabled by default on all Nodes. Immutable nodes have no need of terminal interactions \u2020Transparency of data packets sent for Billing purposes \u2020No Vendor Access to Cloud. Your Cloud contains sensitive business data, as a Vendor we shouldn't have access to it, even in debugging and assistance situations, our only access is via screenshare. \u2020Isolation of System and Kubernetes schedulled workloads. There is no physical method available within the Node for Kubernetes workloads to interact with System Container processes as ContainerD provides solid namespace separation \u2020ETCD access disabled. Control plane is and should be the only allowed mechanism to access Kubernetes core database \u2020Workload Isolation Security Advantages of Virtual Machines (VM) for Containers \u2020Zero Trust Secrets. \u2020Upgrade Flexibility. Just because Cyvive releases an upgrade, it shouldn't necessitate the upgrade of a working cluster. Enterprise has the choice of which upgrades they want to apply and when \u2020 Marked items were premiered by Cyvive as a Kubernetes Operational Platform Networking Security Ingress Egress NameSpace Level Isolation, permitting custom bridging should it be necessary Multi-Cluster Policy Enforecment (or Multi-Cloud Provider as Cyvive is cloud agnostic) \u2020Safe Shadow Traffic Replication (automatic disposal of shadow responses) Transparent Encryption between Nodes Tagging and tracing of routed packets Availability Zone and DataCentre aware networking \u2020 Marked items were premiered by Cyvive as a Kubernetes Operational Platform Scale Cyvive is designed to operate at datacenter scale. Its not unusual for some clients to run 2,500+ nodes at 500 containers per node. In Hybrid, Bare Metal or Cloud environments. When it comes to replacing a DataCenter, the following are important for enablement: \u2020Choice of upgrade paths. Availability Zone blackout or Per Instance Type \u2020CPU Architecture options. AMD64 or AARM64 are both supported Persistent Storage available within the Cluster. ZFS management, and replication functionality baked-in \u2020Control Plane AutoRecovery and Healing. \u2020Control Plane resizing based on node demand. Multi-Cloud or Agnostic implementation. Capable of Policy Enforcement without Mesh Network, spanning multiple clusters. \u2020ETCD Persistence, Recovery and Snapshotting \u2020 Marked items were premiered by Cyvive as a Kubernetes Operational Platform Margin Cloud Providers are in fierce competition with eachother, and the balance of power has never been so in favour of the customer. Specifically, the utilization of Spot or Premptive instances allows a per-hour billing and cost optimization previously untapped. Provided you can migrate the bulk of your Information Technology infrastrcture every hour. With Cyvive , you can, and that's not all: Cyvive is the premier continual Kubernetes optimization platform within the following specifications: Repacking or Condensing of Running services and provisioned infrastructure every 10 minutes. (6 times per hour) \u2020Deep understanding of accessible verses system reserved infrastructure resource allocation \u2020Continual progression with all major cloud providers optimizing Cloud Provisioning against billing functions and reduced spending. Network throughput measured at twice that of standard loopback \u2020Kubernetes Control Plane Resizing ETCD Stacked on the Control Plane, no additional dedicated ETCD instances are required. \u2020 Marked items were premiered by Cyvive as a Kubernetes Operational Platform Speed To gain a full understanding of the Speed benefits Cyvive offers, visit the Governance area.","title":"Understanding"},{"location":"platform/#in-relation-to-cloud-native","text":"Cloud Native Computing Foundaton (CNCF) graduated two significant projects that have disrupted the Information Technology industry at a scarcely precedented scale. Kubernetes and ContainerD . It is no co-incidence that Cyvive is an enabler for both technologies. Kubernetes has been utilized and supported by Cyvive since September 2016 (Kubernetes 1.6.x) ContainerD literally provides the operating system Cyvive has utilized since shortly after Google Kubernetes Engine was released, making us one of the early adopters of the technology.","title":"In Relation to Cloud Native"},{"location":"platform/#enterprise-acceleration","text":"Speed, Scale, Margin ; is the core mantra of most (if not all) Enterprise today. In fact, such is the drive for these three key factors, that the restraint on progress is no longer human related, but reaction related. A clear example in point is, churn rate for unorchestrated containers is roughly once every 6 days , wherease orchestrated containers are 2x a day , or 12 times faster. If your infrastructure is capable of operating at scale and speed, development will rise to meet the restraints.","title":"Enterprise Acceleration"},{"location":"platform/#security","text":"With the advent of DevSecOps there is sane reason why Security is not defacto included with Speed, Scale, Margin . For Cyvive , security is so critical that every part of its operation puts security first. Notable functionality being: \u2020Immutability: Every deployed node is Immutable. From the Control plane, through to storage nodes. If a breach did occur, the node can be terminated without adverse affects to the workload. Container Certification: Containers are by default blacklisted from deployment into Kubernetes, unless they pass required security rules such as No CVE's present that a patch is available for \u2020Deploys into existing Enterprise Setup Cloud Network \u2020Cloud Provisioning continually reviewed and developed in conjunction with Cloud Certified Engineers \u2020TTY and SSH disabled by default on all Nodes. Immutable nodes have no need of terminal interactions \u2020Transparency of data packets sent for Billing purposes \u2020No Vendor Access to Cloud. Your Cloud contains sensitive business data, as a Vendor we shouldn't have access to it, even in debugging and assistance situations, our only access is via screenshare. \u2020Isolation of System and Kubernetes schedulled workloads. There is no physical method available within the Node for Kubernetes workloads to interact with System Container processes as ContainerD provides solid namespace separation \u2020ETCD access disabled. Control plane is and should be the only allowed mechanism to access Kubernetes core database \u2020Workload Isolation Security Advantages of Virtual Machines (VM) for Containers \u2020Zero Trust Secrets. \u2020Upgrade Flexibility. Just because Cyvive releases an upgrade, it shouldn't necessitate the upgrade of a working cluster. Enterprise has the choice of which upgrades they want to apply and when \u2020 Marked items were premiered by Cyvive as a Kubernetes Operational Platform Networking Security Ingress Egress NameSpace Level Isolation, permitting custom bridging should it be necessary Multi-Cluster Policy Enforecment (or Multi-Cloud Provider as Cyvive is cloud agnostic) \u2020Safe Shadow Traffic Replication (automatic disposal of shadow responses) Transparent Encryption between Nodes Tagging and tracing of routed packets Availability Zone and DataCentre aware networking \u2020 Marked items were premiered by Cyvive as a Kubernetes Operational Platform","title":"Security"},{"location":"platform/#scale","text":"Cyvive is designed to operate at datacenter scale. Its not unusual for some clients to run 2,500+ nodes at 500 containers per node. In Hybrid, Bare Metal or Cloud environments. When it comes to replacing a DataCenter, the following are important for enablement: \u2020Choice of upgrade paths. Availability Zone blackout or Per Instance Type \u2020CPU Architecture options. AMD64 or AARM64 are both supported Persistent Storage available within the Cluster. ZFS management, and replication functionality baked-in \u2020Control Plane AutoRecovery and Healing. \u2020Control Plane resizing based on node demand. Multi-Cloud or Agnostic implementation. Capable of Policy Enforcement without Mesh Network, spanning multiple clusters. \u2020ETCD Persistence, Recovery and Snapshotting \u2020 Marked items were premiered by Cyvive as a Kubernetes Operational Platform","title":"Scale"},{"location":"platform/#margin","text":"Cloud Providers are in fierce competition with eachother, and the balance of power has never been so in favour of the customer. Specifically, the utilization of Spot or Premptive instances allows a per-hour billing and cost optimization previously untapped. Provided you can migrate the bulk of your Information Technology infrastrcture every hour. With Cyvive , you can, and that's not all: Cyvive is the premier continual Kubernetes optimization platform within the following specifications: Repacking or Condensing of Running services and provisioned infrastructure every 10 minutes. (6 times per hour) \u2020Deep understanding of accessible verses system reserved infrastructure resource allocation \u2020Continual progression with all major cloud providers optimizing Cloud Provisioning against billing functions and reduced spending. Network throughput measured at twice that of standard loopback \u2020Kubernetes Control Plane Resizing ETCD Stacked on the Control Plane, no additional dedicated ETCD instances are required. \u2020 Marked items were premiered by Cyvive as a Kubernetes Operational Platform","title":"Margin"},{"location":"platform/#speed","text":"To gain a full understanding of the Speed benefits Cyvive offers, visit the Governance area.","title":"Speed"}]}